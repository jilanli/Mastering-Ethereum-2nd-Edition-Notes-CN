# 背景
以太坊的数据越来越多，存储和带宽压力越来越大，非常需要一个扩容方案。

# 多种扩容方案


# L2扩容详解

## 核心原理
KZG证明

## 具体流程

### 数据结构
以太坊的一个Blob(Binary Large Object)的容量是128KB，分为4096个槽位，一个槽位32字节。

### 数据转换
使用一种称为Reed-Solomon Erasure Coding的技术将128KB的数据扩展到256KB。
1. 数据适配
一个数学定理：对于N个点，有且仅有一个N-1阶的多项式曲线包含全部的N个点。因此，将4096个槽位抽象成4096个二位坐标点(i, P(i))，找到对应的4095阶多项式P(x)。一般使用快速傅里叶变换计算。
2. 对于这条曲线，P(0)， P(1)，...， P(4095)属于原始数据；P(4096)， P(4097)，...， P(8191) 属于扩展数据。

### 承诺和证明
1. 生成承诺
根据KZG证明的数据集，生产承诺 $C = [P(s)]_1$
2. 生成扩展数据
使用P(x)在更多的点上生成新的数据，一般是4096到8191。原因是这样可以防止数据错误或者丢失，只要有一半的数据就可以确定多项式P(x)，原始数据就可以恢复。
3. 生成证明
对于全部的8192个点，预先计算每一个点的KZG证明。如果之后验证者来询问每一个插槽的数据，直接返回对应的证明。一般使用FK20算法计算证明。

### 数据广播
证明者不会直接把Blob放到主网中，而是48字节的承诺放到主网中；同时向gossip 网络广播自己的Blob Sidecar

### 数据接收和采样
通过P2P网络接收一个区块，其中有KZG承诺。节点随机选择几个索引，向网络中的其他节点发送请求，查询对应索引的数据和承诺的证明。

### 数据验证
现在已经有了数据y和证明 $\pi$ ，使用Bilinear Pairing检查

$$e(\pi, [s - z]_2) = e(C - [y]_1, [1]_2)$$

如果等式平衡，那么这个索引的数据就是可信的。只需要验证少数几个索引，一般是16个，就可以证明Blob中的所有数据都是正确的。








In the 2026 roadmap, Ethereum uses Subnet Sampling. No single validator is responsible for holding the whole blob.

The Gossip Network is split into many "columns" and "rows."

Your node is assigned to watch just a few specific "columns."

Because thousands of nodes are all watching different columns, the entire blob is guaranteed to be held by the network collectively.
