# 背景
以太坊的数据越来越多，存储和带宽压力越来越大；同时在26年之前，以太坊只能承载大约30的TPS，交易的手续费也水涨船高，非常需要一个扩容方案，提升承载力，降低交易成本。

# 多种扩容方案
早在2024年，通过EIP-4844提案引入Blob，很大程度上提升了以太坊的容量，是以太坊扩容道路上的一次里程碑。
扩容方案其实有很多种，这里只提其中两种：

1. Optimistic Rollups
Arbitrum，Optimism和Base都使用了这种扩容方案。在链外执行交易，并将数据通过Blob发送到L1网络中。

2. ZK Rollups
zkSync，Startnet和Polygon zkEVM均采取此方案，同样是在链外交易，但是会将数据和加密证明一起发送到L1网络，相比Optimistic方案更加复杂但是理论上更安全，容量上限更高。


# 扩容方案详解

## EIP-4844核心原理 KZG证明
KZG证明不仅给数据加上了指纹，更可以证明现有的数据是一个完整数据的一部分。

### 计算承诺
通过数学抽象，将Blob数据看成一系列字节，而每个字节都可以看做一个数字，这些数字就是一个多项式的系数，将Blob数据转变成了一个多项式。一个Blob有4096个槽位，因此可以抽象成一个4095阶的多项式。 

计算这个多项式在秘密点s的结果作为Blob的承诺

$$
C = a_0 \cdot G + a_1 \cdot (sG) + a_2 \cdot (s^2G) + \dots + a_{4095} \cdot (s^{4095}G)
$$

### 计算证明

对于Blob中的任意一个槽位，其序号z抽象为一个横轴的坐标，

$$y = f(z) = \sum_{i=0}^{n} a_i z^i = a_0 + a_1 z + a_2 z^2 + \dots + a_n z^n$$

由于(z,y)肯定满足多项式，因此下面的多项式一定可以整除

$$q(x) = \frac{f(x) - y}{x - z}$$

可以写成下面的形式

$$f(x) - y = (x - z) \cdot q(x)$$

其中

$$q(x) = \sum_{i=0}^{n-1} b_i x^i = b_0 + b_1 x + b_2 x^2 + \dots + b_{n-1} x^{n-1}$$

可以计算出证明结果

$$\pi = q(s) \cdot G_1 = b_0 G_1 + b_1 (s G_1) + b_2 (s^2 G_1) + \dots + b_{n-1} (s^{n-1} G_1)$$


### 验证
L1网络中的验证节点可以通过下面的数学流程进行验证

$$e(C - y \cdot G_1, G_2) = e(\pi, s \cdot G_2 - z \cdot G_2)$$

其中C表示承诺， $\pi$ 是证明，s是未知的秘密点，z是待验证的槽位序号，y是槽位中的数据对应的数字，e() 是bilinear pairing 函数，有一个性质  $$e(a \cdot P, b \cdot Q) = e(P, Q)^{ab}$$ 。

将等式的左右两边分别展开

$$e(C - y \cdot G_1, G_2) = e(f(s) \cdot G_1 - y \cdot G_1, G_2) = e((f(s) - y) \cdot G_1, G_2)$$

$$e(\pi, s \cdot G_2 - z \cdot G_2) = e(q(s) \cdot G_1, (s - z) \cdot G_2) = e(q(s) \cdot (s - z) \cdot G_1, G_2)$$

因为 $$f(x) - y = (x - z) \cdot q(x)$$ 所以 $$f(s) - y = (s - z) \cdot q(s)$$

因此等式的左右两边相等。

### 网络
1. 主网共识层增加一个子网 Blob sidecar subnet
Blob sidecar subnet网络传播Blob数据，但是承诺还是作为交易数据的一部分发送到Beacon block subnet。每一个以太坊的验证者都可以看到和验证网络中的所有数据。

2. Blob Gossip Subnets
L2网络中的Blob并不会塞进主网，而是传进了Gossip子网。以太坊中的验证者需要请求Gossip Network来采样验证。

3. L2网络
L2层的交易就在这里发生，相比于以太坊的公网是一个私人的部分，比如 Arbitrum 或者 Optimism。每一个L2网络的Blob对应一个L1网络的交易，实际的Blob的数据被分发到L1网络的 Blob sidecar 子网中，

## Optimistic Rollups

### 核心概念
将L2的交易打包进Blob，将Blob的承诺作为一个交易发送到以太坊的L1，默认将所有的交易当做有效的（这也是optimistic这个词的本意），但是允许任何人在有效期内检查交易。

### 架构组件

1. Sequencer Node（L2）
  * 执行交易
  * 将交易批量打包
  * 通过Blob将数据发送到L1（EIP-4844）
  * 经常是中心化的

2. Full Node（L2）
  * 从L1下载数据
  * 在本地执行交易
  * 维护L2网络的状态
  * 可以检查作弊

3. Verifiers/Challengers
  * 监视sequencer防止出现无效的状态转移
  * 如果发现问题提交证据
  * 任何人都可以是一个验证者

4. L1 Smart Contracts
  * 保存状态根
  * 管理存款和取款
  * 处理作弊验证
  * 在挑战期过了之后（一般是7天）将数据固定下来

### 具体流程

1. 交易执行（L2）
```
用户提交交易请求 → Sequencer 接收请求 → 在 L2 执行交易 → 更新 L2 状态 → 添加进批处理
```

2. 批量传输（L2 → L1）
使用EIP-4844的Blob
```
Sequencer创建一批交易 
         ↓
打包进一个Blob中 (大约125KB)
         ↓
将Blob提交到L1:
  - Blob数据 → L1共识层 (使用Blob sidecar子网)
  - Blob对应的承诺 (KZG) → L1 执行层(承诺包装在一个交易中)
  - 新的L2状态根 → L1 rollup的合约中
         ↓
L1中的验证者会保存18天
```

3. Challenge Period (7天)

```
Batch posted → Challenge period starts (7 days)
                        ↓
              Verifiers download blob from L1
                        ↓
              Execute transactions locally
                        ↓
         ┌──────────────┴──────────────┐
         │                             │
    Valid batch?                  Invalid batch?
         │                             │
         ↓                             ↓
   No action needed            Submit fraud proof
         │                             │
         ↓                             ↓
   After 7 days                 Batch reverted
   → Finalized                  → Sequencer slashed
                                → State rolled back
```

4. Finalization
如果没有舞弊被发现，7天后，这批数据就是终态，可以处理withdrawal。

### L1和L2的非对称性
L1和L2网络的一个核心区别是信任程度不同。数据从L1转移到L2是安全的并且速度可以很快（deposit）；但是数据从L2转移到L1就需要安全验证等流程，速度慢（withdrawal）。

### 数据结构
以太坊的一个Blob(Binary Large Object)的容量是128KB，分为4096个槽位，一个槽位32字节。

### 数据转换
使用一种称为Reed-Solomon Erasure Coding的技术将128KB的数据扩展到256KB。
1. 数据适配
一个数学定理：对于N个点，有且仅有一个N-1阶的多项式曲线包含全部的N个点。因此，将4096个槽位抽象成4096个二位坐标点(i, P(i))，找到对应的4095阶多项式P(x)。一般使用快速傅里叶变换计算。
2. 对于这条曲线，P(0)， P(1)，...， P(4095)属于原始数据；P(4096)， P(4097)，...， P(8191) 属于扩展数据。

### 承诺和证明
1. 生成承诺
根据KZG证明的数据集，生产承诺 $C = [P(s)]_1$
2. 生成扩展数据
使用P(x)在更多的点上生成新的数据，一般是4096到8191。原因是这样可以防止数据错误或者丢失，只要有一半的数据就可以确定多项式P(x)，原始数据就可以恢复。
3. 生成证明
对于全部的8192个点，预先计算每一个点的KZG证明。如果之后验证者来询问每一个插槽的数据，直接返回对应的证明。一般使用FK20算法计算证明。

### 数据广播
证明者不会直接把Blob放到主网中，而是48字节的承诺放到主网中；同时向gossip 网络广播自己的Blob Sidecar

### 数据接收和采样 DAS
通过P2P网络接收一个区块，其中有KZG承诺。节点随机选择几个索引，向网络中的其他节点发送请求，查询对应索引的数据和承诺的证明。数据

### 数据验证
现在已经有了数据y和证明 $\pi$ ，使用Bilinear Pairing检查

$$e(\pi, [s - z]_2) = e(C - [y]_1, [1]_2)$$

如果等式平衡，那么这个索引的数据就是可信的。只需要验证少数几个索引，一般是16个，就可以证明Blob中的所有数据都是正确的。

### 数据保存
Blob数据只保存在验证节点中。其中区块的提议者会保存全部的数据，其他的验证者只会保留一小部分数据，数据只会保留18天。

如果实行的协议中没有DAS（post-EIP-4844），那么所有的验证者都会保存完整的Blob数据。



路线规划

In the 2026 roadmap, Ethereum uses Subnet Sampling. No single validator is responsible for holding the whole blob.

The Gossip Network is split into many "columns" and "rows."

Your node is assigned to watch just a few specific "columns."

Because thousands of nodes are all watching different columns, the entire blob is guaranteed to be held by the network collectively.
