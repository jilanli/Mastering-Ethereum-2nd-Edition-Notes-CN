# 第 17 章：零知识证明 (Zero-Knowledge Proofs)

在本章中，我们将一同探索零知识证明 (ZK) 密码学那引人入胜的世界，并深入了解它是如何完美契合以太坊路线图的。正是这项技术，让以太坊实现真正的扩容 (Scaling) 并承载主流人群对区块空间的爆发式需求成为可能。
零知识技术是一个极其复杂的课题，其底层构建在大量的数学规律之上，我们无法在此穷尽所有细节。本章的目标是确保你能理解，为什么零知识密码学能为以太坊带来独特的机遇，以及它如何丝滑地融入其扩容路线图。
在本章结束时，你将从宏观层面掌握零知识密码学的运作机制，了解它的核心特性，以及以太坊将如何利用它来优化协议性能。

## 发展简史
零知识证明 (Zero-Knowledge Proofs) 最早由 Shafi Goldwasser、Silvio Micali 和 Charles Rackoff 在 1985 年发表的论文[《交互式证明系统的知识复杂度》](https://oreil.ly/a6KH6)中提出。在该论文中，他们将零知识证明描述为一种向对方证明“某件事是真实的”的方法，且除了“该声明确实属实”这一事实外，不会泄露任何其他信息。尽管零知识证明早在 20 世纪 80 年代就被发现，但其早期的实际应用场景非常有限。

一切在 2011 年迎来了转机。[BIT+11](https://oreil.ly/C6HvM) 论文引入了 SNARKs（简洁非交互式知识论证），为针对任意计算生成零知识证明提供了一个理论框架。两年后的 2013 年，[Pinocchio PGHR13](https://oreil.ly/4uU6x) 论文实现了首个通用型 SNARK 的工程化落地，使 SNARKs 在现实应用中变得可行。人类历史上第一次实现了：可以证明一个通用程序已被正确执行，而无需重新运行该程序，且无需泄露实际的计算细节。

一场革命就此拉开序幕。从那时起，零知识证明领域以惊人的速度演进：
* 2016 年：[Groth16 算法](https://oreil.ly/rxlOL)显著提升了 zk-SNARKs 的效率，缩减了证明大小 (Proof Size) 和验证时间 (Verification Time)。凭借其卓越的简洁性，Groth16 至今仍被广泛使用（例如去中心化混币应用 Tornado Cash 就在链上使用它）。
* 2017 年：[Bulletproofs](https://oreil.ly/ZUeIe) 带来了突破性进展，消除了对可信设置 (Trusted Setup) 的需求（我们将在后续章节深入探讨其定义），代价是证明体积较大。目前，隐私代币门罗币 (Monero) 使用它来混淆交易金额。
* 2018 年：[zk-STARKs](https://oreil.ly/TCnTT) 问世。它不仅不需要可信设置，还具备抗量子安全性 (Post-quantum Security)。它目前是以太坊 L2 项目 Starknet 的密码学基石。
* 2019 年：[PLONK](https://oreil.ly/3453_) 和 [Sonic](https://oreil.ly/f6_Sq) 作出了重大贡献，引入了通用且可更新的可信设置。这使得 SNARKs 在通用应用中更加灵活实用，并持续影响着现代 ZK 系统。

如今，零知识证明仍处于高速发展中。最近的进展聚焦于优化证明生成时间 (Proving Time)、递归效率 (Recursion Efficiency) 以及 zkEVM 和现代 zkVM 等实际应用。新的架构和优化方案层出不穷，不断推高零知识技术的边界。

这一领域的蓬勃发展主要得益于加密货币行业带来的资金注入。以太坊基金会 (EF) 自身也通过提供多项资助 (Grants) 以及设立专门的研究团队，持续为该课题贡献力量。

## 定义与特性

现在，让我们进入细节，明确什么是零知识证明以及它必须具备哪些特性。正如前文所述，零知识证明是一种协议，允许一方（通常称为证明者 Prover，简称 P）向另一方（通常称为验证者 Verifier，简称 V）证明某个陈述是真实的，且除了“该陈述确实为真”这一事实外，不泄露任何额外信息。

让我们将几个重要定义形式化：

**陈述 (Statement)**

正在被证明的断言。陈述是公开的，任何人都可以验证，且不包含任何私密信息。

**见证数据 (Witness)**

证明陈述属实的秘密信息。见证数据仅由证明者知晓。

**证明 (Proof)**

这是一个加密对象，它能在不泄露“见证数据”的前提下，让验证者确信陈述是真实的。

所有的零知识证明系统都必须遵循以下三个特性：

**完备性 (Completeness)**

如果证明者 P 手中的陈述是真实的，那么只要按照协议规则操作，P 就一定能计算出有效的零知识证明。不存在证明者遵守了所有规则却无法生成有效证明的情况。

**可靠性 (Soundness)**

任何恶意证明者都不可能为错误的陈述伪造出有效的证明。如果验证者接受了一个证明，那么唯一可能的解释就是证明者确实遵循了协议规则，并以真实的陈述为起点。

**零知识性 (Zero-knowledge)**

顾名思义，验证者在执行协议的过程中，除了获知初始陈述的有效性外，无法获取任何其他信息。

## 以太坊如何利用零知识证明

你可能会好奇，为什么这种极具前沿性的密码学技术对以太坊的未来发展和路线图如此重要。答案其实非常直接。

在以太坊的语境下，零知识证明系统的真正威力在于：它们使得验证一个陈述的有效性变得可能，而验证者无需亲自重复得出该陈述所需的全部计算过程。首先，由证明者（Prover）计算出某个特定的陈述并附带一份零知识证明；随后，所有的验证者（Verifiers）只需运行零知识协议，即可去信任化 (Trustlessly) 地确认该陈述属实，而无需像证明者那样进行同等规模的计算。

细心的读者可能已经发现，这与以太坊的某个环节完美契合：区块执行与状态更新——换句话说，就是 EVM 状态转换函数 (EVM State Transition Function)。每一个新区块都会通过处理其中包含的所有交易，来更新当前的以太坊状态。图 17-1 很好地展示了这一过程。

![Figure 17-1](<./images/figure 17-1.png>)

图 17-1：EVM 状态转换函数

你可以将 EVM（以太坊虚拟机） 想象成一个“黑盒”：它的输入是区块链的当前状态 (Current State) 和包含大量交易的新区块，输出则是更新后的新状态。目前，当一个以太坊全节点收到新区块时，它必须重新执行该区块中的所有交易，以便在无需依赖任何可信第三方的情况下，去信任化地更新状态。

这种方法的主要问题在于，区块执行成为了潜在的性能瓶颈，因为它属于计算密集型任务。你最终必须在“全节点为保持与主网同步所需的硬件配置”与“网络所需的去中心化程度”之间寻找平衡。如果你想通过提高全节点门槛来扩容，就会损害去中心化，因为财力有限的普通参与者将无法负担运行全节点的成本。反之，如果你为了让任何人都能运行节点而维持较低的硬件要求，那么区块链能够处理的最大吞吐量就会受到限制。以太坊始终倾向于去中心化这一侧，保持较低的硬件门槛，以支持单人质押 (Solo Stakers) 和全节点运行者的存在。

这正是零知识证明系统大显身手的地方。如果有一种方法，能让全节点在不执行任何交易的情况下（即无需进行沉重的 EVM 状态转换计算），就能去信任化地更新状态，结果会怎样？这个想法可以总结如下：
1. 执行与证明： 少数参与者通过执行新区块中的所有交易来完成实际的 EVM 计算，并生成链的更新状态。
2. 生成证明： 这些参与者生成一份零知识证明，用以证明该状态的有效性，并将其与更新后的状态一起分发给所有全节点。
3. 极速验证： 当其他全节点收到新的链状态和 ZK 证明时，它们只需验证证明的有效性。如果证明有效，它们就可以去信任化地将本地状态更新为收到的新状态。

通过这种方式，虽然仍需要一些节点（可能由财力雄厚的机构维护）来执行所有交易，但其他所有节点都可以维持极低的运行成本，因为它们只需验证证明。你可以大幅提升第一类节点的硬件要求，从而处理极高的吞吐量，同时凭借零知识证明的“魔法”依然保持高度的去中心化。

到目前为止，我们一直假设生成和验证 ZK 证明是快速且简便的。事实上，只有当“验证 ZK 证明”比“重新执行区块内所有交易”快得多时，上述方案才有意义。就现状而言，实现这一特性仍具挑战。但这本质上是一个工程优化问题：这只是“何时”实现的问题，而不是“能否”实现的问题。我们很快就会达到那个临界点——能够实时为以太坊区块生成并验证零知识证明。如果你对该领域的进展感兴趣，Ethproofs 是一个非常值得关注的网站。

## L2 同样受益于 ZK 技术
以太坊主网并不是零知识证明技术的唯一受益者。事实上，正如你在第 16 章中可能已经读到的，有一类被称为 ZK-rollups 的汇总网络。顾名思义，它们利用零知识证明系统来证明 EVM 的执行过程，从而向主链提交其状态更新，并附带一份确保新状态计算正确的零知识证明。

你可能会纳闷：既然前面提到目前还无法实现以太坊区块的实时证明，那 ZK-rollups 又是如何使用这项技术的呢？答案是：它们并没有追求实时证明，甚至不需要为 L2 的每一个区块都进行实时证明。通常，它们每隔一小时左右提交一次聚合零知识证明 (Aggregate ZK-proof)，用以证明自上次更新以来到最新状态之间的所有状态变更都是正确执行的。

每份零知识证明之间的时间间隔，仅会影响 Rollup 本身的最终确认性 (Finality) 时间。如果每小时提交一次证明，这意味着平均而言，你需要等待 30 分钟，你的交易才能在 L1（第一层主网）上被视为真正的“最终确认”。

## 一个小案例
为了更直观地理解零知识证明系统是如何运作的，让我们从一个简单的小例子开始：划分问题 (Partition Problem)。这是一个著名的数学问题，其任务是：“判断一个给定的正整数多重集 $S$ 是否可以被划分为两个子集 $S_1$ 和 $S_2$，使得 $S_1$ 中所有数字之和等于 $S_2$ 中所有数字之和。”

> [!Note]
> 划分问题属于判定问题 (Decision Problem)，而以太坊依赖零知识证明来验证的是执行轨迹 (Execution Traces)。尽管以太坊使用 ZKP 的主要场景是验证计算执行过程，但通过划分问题来推演，仍然是建立“零知识证明系统如何工作”直观认知的绝佳方式。

假设我们有一个集合 $S = [1, 1, 5, 7]$，我们可以通过将其划分为 $S_1 = [1, 1, 5]$ 和 $S_2 = [7]$ 来满足要求（两边之和均为 7）。但并不是所有的集合都能找到正确解，例如，如果 $S = [1, 1, 5, 8]$，那么由于总和为奇数，根本无法将其划分为两个和相等的子集。

划分问题是 NP 完全 (NP-complete) 的。这意味着目前不存在能在多项式时间内解决该问题的算法——也就是说，如果存在解，目前没有办法在极短的时间内找到它，或者证明解不存在。

### 让我们来证明它

划分问题的结构完美契合了我们之前看到的零知识证明系统的特性。事实上，既然找到解的过程非常困难，那么将“寻找解”的计算压力外包给一个配备了超级计算机的、资源丰富的证明者 (Prover) 就会变得非常有意义。接着，利用零知识技术，证明者可以向所有人证明它确实找到了一个有效解，而无需其他人进行同样繁重的计算，同时也不会泄露该解的具体内容。

为了让划分问题适配零知识证明系统，我们需要对其进行一点小小的改动。假设我们有一个正整数列表 $s$。如果另一个列表 $a$ 满足以下条件，我们就称其为满足赋值 (Satisfying Assignment)：
1. 长度相等： len(s) == len(a)
2. 元素限定： $a$ 中的所有元素必须是 $1$ 或 $-1$
3. 点积为零： $s$ 和 $a$ 的点积为 $0$

请注意，这种构造方式与之前的划分问题是完全等价的。如果我们沿用之前的初始列表 $S = [1, 1, 5, 7]$，那么对应的满足赋值 $a$ 就是：

$$a = [1, 1, 1, -1]$$

你可以手动校验这三个条件是否全部成立：
1. len(s) = 4 且 len(a) = 4（成立）
2. $a$ 的元素全是 $1$ 或 $-1$（成立）
3. 点积： $1 \times 1 + 1 \times 1 + 1 \times 5 + (-1) \times 7 = 1 + 1 + 5 - 7 = 0$（成立）

两个等长列表之间的点积 (Dot Product) 的计算方法是：将第一个列表中的每个成员与第二个列表中的对应元素相乘，然后将所有结果相加。从技术角度来说，如果我们有两个长度均为 $n$ 的列表 $s = [s_0, s_1, s_2, \dots, s_n]$ 和 $a = [a_0, a_1, a_2, \dots, a_n]$，则点积的计算公式如下：

$$s \cdot a = \sum_{i=0}^{n} s_i a_i = s_0 a_0 + s_1 a_1 + s_2 a_2 + \dots + s_n a_n$$

当然，我们可以直接把列表 $a$ 发送给验证者，让他们直接校验这是否为一个有效解。但这样做会泄露解的具体内容，从而违反了零知识证明中“不泄露任何信息”的初衷。为此，我们开始生成另一个列表 $w$，即部分和列表 (Partial-sum list)。也就是说，$w[i]$ 等于列表 $s$ 和 $a$ 截至索引 $i$ 的部分点积。在零知识证明系统的语境下，$w$ 也被称为见证数据 (Witness)。沿用之前的例子，我们可以计算出 $w$：

$$w = [1, 2, 7, 0]$$

请注意，如果 $a$ 是一个有效的“满足赋值”，那么 $w$ 的最后一个元素必定为 $0$（因为点积为 $0$）。为了让证明系统更高效地运行，我们对目前构建的证明过程进行一点小小的修改。具体来说，我们将列表 $w$ 的最后一个元素移动到首位，因此之前的 $w$ 现在变成了：

$$w = [0, 1, 2, 7]$$

太棒了！这个列表 $w$ 具有一个非常酷的特性：

$$|s[i]| = |w[i + 1] - w[i]|$$

你可以亲自校验一下这个等式的有效性：

$$|s[0]| = |w[1] - w[0]| = |1 - 0| = |1| = 1$$

$$|s[1]| = |w[2] - w[1]| = |2 - 1| = |1| = 1$$

$$|s[2]| = |w[3] - w[2]| = |7 - 2| = |5| = 5$$

$$|s[3]| = |w[0] - w[3]| = |0 - 7| = |-7| = 7$$

请注意，在计算 $s[3]$ 时，我们需要访问 $w[4]$，但由于 $w$ 只有四个元素（且索引从 $0$ 开始）， $w[4]$ 并不存在。不过，这里有一个非常简单的解决方案：你只需要像对待循环列表 (Cyclical List) 一样，回到 $w$ 的第一个元素即可。

验证者可以要求查看 $w$ 中任意两个相邻的元素，并检查上述关系是否成立。请记住，验证者是有权访问列表 $s$ 的，因为 $s$ 是公开可见的，它代表了这个问题的输入；但验证者无法访问 $a$（即满足赋值），因为 $a$ 代表了解析方案。如果等式成立，则意味着证明者确实知道该问题的一个有效解 $a$。

#### 存在的问题
到目前为止，我们构建的是一个非常原始（Naive）的证明系统。事实上，它存在三个严重的问题：
1. 概率可靠性不足： 此前我们假设，一旦验证者请求了 $w$ 的两个相邻元素且等式成立，就完成了验证。但这并不严谨。仅凭一次查询，验证者无法完全确定；他们必须对 $w$ 的相邻元素进行多次随机查询，才能以极高的概率确认证明者没有作弊。
2. 缺乏数据承诺（一致性问题）： 虽然验证者可以校验解的正确性，但该系统高度依赖证明者的诚信。如果证明者心怀不轨呢？当验证者请求 $w$ 的两个相邻元素时，证明者可能会临时编造两个恰好满足等式的随机数，而不是基于同一组固定的 $w$ 列表进行回答。
3. 违反零知识原则： 最重要的是，这个系统并不是零知识的。通过询问 $w$ 的连续元素，验证者实际上获取了关于“满足赋值 $a$”的大量信息。验证者知道 $w$ 的构造方式，因此他们掌握的 $w$ 越多，推断出最终解 $a$ 的可能性就越大。现在，让我们着手解决这些问题，尝试构建一个更完善的证明系统。

### 零知识化 (Zero Knowledge)
现在，让我们为系统引入“零知识性”。我们目前构建的协议存在一个核心缺陷：我们将 $w$ 的真实数值直接发送给了验证者，这会导致验证者推断出关于 $a$ 的大量信息。为了在实践中观察这一点，让我们模拟证明者与验证者之间的两步交互。
1. 第一步交互： 验证者请求 $w[1]$ 和 $w[2]$，并检查 $|w[2] - w[1]| = |s[1]|$ 是否成立。证明者提供了 $w[1] = 1$ 和 $w[2] = 2$。验证者确认等式成立：

$$|s[1]| = |w[2] - w[1]| = |2 - 1| = 1 = 1$$
   
2. 第二步交互： 接着，验证者发起了另一次查询：请求 $w[2]$ 和 $w[3]$。证明者提供了 $w[2] = 2$ 和 $w[3] = 7$。验证者校验等式：

$$|s[2]| = |w[3] - w[2]| = |7 - 2| = 5 = 5$$

通过这两次交互，验证者已经掌握了 $w$ 中的三个元素：

$w[1]=1$

$w[2]=2$

$w[3]=7$

由于验证者已经知道了 $s = [1, 1, 5, 7]$ 并且了解 $w$ 的计算方式，他们可以推导出解 $a$ 的初始部分等于 $[1, 1, 1]$，因为这是得到 $w[3] = 7$、 $w[2] = 2$ 和 $w[1] = 1$ 的唯一途径。

我们需要找到一种方法来掩盖 $w$ 的真实值，但同时又能让新的 $w$ 与输入列表 $s$ 之间满足原有的关系。为了实现这一点，我们需要以一种非常特殊的方式加入随机性 (Randomness)。符号翻转： 

首先，针对列表 $a$，我们抛一枚硬币。如果是正面，保持原样；如果是反面，我们将所有元素的符号取反（即 $1$ 变成 $-1$， $-1$ 变成 $1$）。请注意，这种改变并不会破坏该问题中“满足赋值 $a$”的三大核心性质（点积依然为 $0$）。

接着，我们选取一个随机整数 $r$。我们按照之前的方法计算 $w$，但要在 $w$ 的每一个元素上都加上这个 $r$。即便做了这些改动， $s$ 和 $w$ 之间的核心关系（差值的绝对值等于 $s[i]$）依然成立。

每当验证者发起一次新的查询，我们（证明者）都必须重新抛一次硬币，并重新计算一个不同的随机值 $r$。通过这种方式，验证者虽然仍能校验等式的有效性，但他们无法获取关于 $a$ 的任何有效信息，因为所有的 $w$ 值在他们看来都是随机的。

让我们做一个小演示。请记住，作为证明者的我们，手中同时持有 $s$ 和 $a$：

$$s = [1, 1, 5, 7]$$

$$a = [1, 1, 1, -1]$$

现在，验证者请求获取 $w[1]$ 和 $w[2]$，以校验 $|w[2] - w[1]| = |s[1]|$ 是否成立。

首先，我们需要抛硬币来决定是否更改 $a$ 的所有数值。结果是反面，所以我们需要翻转所有符号，$a$ 变成了：

$$a' = [-1, -1, -1, 1]$$

接着，我们计算出一个随机值 $r = 4$。按照之前的方法计算 $w$，并给其中的每一个元素都加上 $r$：

$$w = [0, -1, -2, 7]$$

$$w' = [4, 3, 2, -3]$$

我们提供 $w'[1] = 3$ 和 $w'[2] = 2$ 给验证者。

验证者依然可以确认等式的有效性：

$$|w'[2] - w'[1]| = |2 - 3| = |-1| = 1$$

现在，验证者进行了另一次查询，请求获取 $w[2]$ 和 $w[3]$。同样地，我们需要抛硬币来决定是否更改 $a$ 的所有数值。这次是正面，所以我们不改变符号。

接着，我们计算出一个随机值 $r = 1$。我们计算 $w$ 并给每个元素加上 $r$：

$$a = [1, 1, 1, -1]$$

我们提供 $w''[2] = 3$ 和 $w''[3] = 8$。验证者依然可以确认等式的有效性：

$$|s[2]| = |w''[3] - w''[2]| = |8 - 3| = 5$$

但现在，验证者无法获取关于满足赋值 $a$ 的有效信息。事实上，他们现在掌握的信息如下：

$$w'[1] = 3$$

$$w'[2] = 2$$

$$w''[2] = 3$$

$$w''[3] = 8$$

对于验证者来说，不同查询中得到的 $w$ 值看起来都是随机的，因此他们无法还原出赋值方案 $a$。

太棒了！我们成功地为证明系统引入了零知识性。现在，让我们来解决“恶意证明者”的问题。

#### 证明者承诺 (Prover Commitment)
我们需要解决的问题是，证明者可能会欺骗验证者，提供完全编造的数字，而不是计算出的见证值 $w$ 的真实数值。这非常糟糕，因为证明者将能够为虚假陈述提供有效的证明——也就是说，即使证明者实际上并没有满足条件的赋值 $a$，他们也有可能诱导验证者相信他们确实拥有。

我们需要找到一种方法，确保证明者无法在不被发现的情况下撒谎。从本质上讲，我们需要证明者在向验证者提供所有 $w$ 值之前，先对这些值进行承诺（commitment）。

这正是默克尔树（Merkle trees）再次发挥作用的地方。我们在第 14 章介绍过它们，所以在这里不再详细讨论它们的工作原理。

让我们通过一个新示例来看看实践中的新构造。我们（证明者）拥有：

$$s=[1,1,5,7]$$

$$a=[1,1,1,-1]$$

我们抛硬币，结果是正面，所以我们不需要更改赋值方案 $a$ 的正负号。接着，我们通过计算 $a$ 和 $s$ 的点积（在首尾元素之间进行切换/累加）来计算 $w$：

$$w = [0, 1, 2, 7]$$

我们计算出一个随机值 $r = 8$，并将其加到 $w$ 的每个元素中：

$$w' = [8, 9, 10, 15]$$

现在我们需要对 $w'$ 的所有数值进行承诺，并将该承诺发送给验证者，以此确保如果我们通过提供虚假的 $w'$ 值进行欺骗，这种行为将能被轻易发现。图 17-2 展示了以 $w'$ 的所有数值作为叶子节点所构建的默克尔树。

![Figure 17-2](<./images/figure 17-2.png>)

图 17-2. 使用 $w'$ 值构建的默克尔树

默克尔根（Merkle root）是最终发送给验证者的承诺（commitment）。

此时，验证者开始进行第一次查询：$w'[1]$ 和 $w'[2]$。我们可以向验证者提供 $w'[1]=9$ 和 $w'[2]=10$，随后他们可以进行如下检查：

$$|s[1]| = |w'[2] - w'[1]| = |10 - 9| = 1$$

由于 $|s[1]|=1$，等式成立。现在，验证者需要确保我们没有作弊，因此他们还会要求证明者提供“验证路径（Verification Path）”。该路径包含了验证者自行重建默克尔树所需的所有数据，以便检查生成的默克尔根是否与我们之前发送的承诺一致。如果一致，他们就能确信我们没有作弊；否则，他们会立即发现我们在行骗。

具体来说，针对此次查询的验证路径包含：
* 哈希值 8 (Hash 8)
* 哈希值 15 (Hash 15)

通过这种方式，验证者可以重新构建默克尔树直至根部，并验证承诺。因此，我们将 Hash 8 和 Hash 15 发送给验证者，验证者检查承诺的有效性，最终，本次查询结束。不过，你可能已经发现了一个新问题。事实上，由于验证路径的要求，我们最终发送了一些关于 $w'$ 的额外数据：Hash 8 和 Hash 15。虽然从计算上来说，逆转哈希函数（即从哈希值中还原出实际数值 8 和 15）是不可行的，但一个怀有恶意的验证者可能会尝试暴力破解攻击（Brute-force attack），并可能成功找出一部分我们并不打算公开的默克尔树。幸运的是，有一个简单而巧妙的技巧可以解决这个问题。

### 为承诺增加随机性
这个思路与我们之前为证明系统增加零知识属性的做法类似。这一次，我们需要为承诺（commitment）本身增加随机性，以确保在验证路径中不会泄露任何关于 $w$（或 $w'$）的信息。当我们创建默克尔树时，不再仅仅使用 $w'$ 每个元素的准确值进行哈希来作为叶子节点，而是额外添加一个随机字符串，且这个字符串不会提供给验证者。图 17-3 展示了使用这种新方法构建的默克尔树。

![Figure 17-3](<./images/figure 17-3.png>)

图 17-3. 为实现零知识属性而增加随机性的默克尔树

在这个示例中，我们使用了字符串 "eth" 来遮掩见证值 $w'$ 的每一项。请注意，如果你没有这个秘密字符串，就不可能解码出实际数值。现在，当我们在验证路径中向验证者发送 hash 8 和 hash 15 时，他们对哈希背后的具体 $w'$ 数值完全无从知晓。即使他们尝试暴力破解攻击，由于不知道我们用于进一步隐藏 $w'$ 项的秘密字符串，攻击也无法奏效。

### 结论？或者还没结束……

我们做到了！我们成功地为最初的划分问题创建了一个（非常天真且基础的）零知识证明系统！

你可能仍在想：“这是一个很棒的证明系统，但它仍然需要证明者和验证者之间进行大量的交互。他们必须同时在线，才能确保协议成功运行。有没有办法修复这个问题，将这种交互式零知识证明系统转化为非交互式零知识证明系统呢？”

你说得太对了。我们的系统确实需要证明者和验证者之间的交互才能正常工作，这对于大多数应用场景来说确实非常麻烦。我们再次走运了（运气真好，对吧？）。有一篇科学论文可以帮助我们。

## Fiat-Shamir 启发式（Fiat-Shamir Heuristic）

1986 年，两位著名的密码学家阿莫斯·菲亚特（Amos Fiat）和阿迪·萨莫尔（Adi Shamir）发表了题为[《如何证明你自己：身份识别与签名问题的实用解决方案》](https://oreil.ly/TGfa-)（"How to Prove Yourself: Practical Solutions to Identification and Signature Problems"）的论文。在文中，他们发明了一种至今仍被广泛使用的转换协议，并以他们的名字命名：Fiat-Shamir 启发式（Fiat-Shamir heuristic）或 Fiat-Shamir 变换。

> [!Note]
> 阿迪·萨莫尔（Adi Shamir）是密码学界的一位真正的传奇人物：他是 RSA 算法中的“S”，RSA 是最早也是应用最广泛的公钥加密系统之一。阿莫斯·菲亚特（Amos Fiat）则是他在以色列魏茨曼科学研究所（Weizmann Institute of Science）的同事。

Fiat-Shamir 启发式是一种协议，它可以通过使用加密哈希函数替代验证者的随机挑战，将交互式零知识证明系统转变为非交互式系统。

如果你思考一下我们在目前建立的系统中验证者必须做的事情，你会发现其本质就是给证明者一些随机数（即查询索引），证明者必须利用这些随机数来生成对应的证明。

记住，我们过去常说：“现在验证者要求查看 $w[1]$ 和 $w[2]$。”这可以转化为验证者将数字 1 和 2 交给证明者，以便为 $w[1]$ 和 $w[2]$ 创建证明。

我们可以将原始的交互式协议总结如下（跳过证明者创建见证值 $w$ 并将其调整为 $w'$ 的部分）：
1. 证明者生成对 $w'$ 的承诺并将其发送给验证者。
2. 验证者发送一个随机挑战——即一个查询请求。
3. 证明者发送对该挑战的响应——即一个证明。
4. 验证者验证证明的有效性。

对于验证者提出的每一个不同查询，这个过程都会重复进行。这一切之所以奏效，是因为证明者预先并不知道验证者会提出哪些查询——对证明者来说，这些查询是随机的。因此，如果我们能找到一种方法，让证明者自己以一种随机但可预测的方式生成所有查询，我们就能将整个过程转变为非交互式协议。

在 1986 年的论文中，Fiat 和 Shamir 建议使用哈希函数作为“随机预言机”，来模拟验证者的随机挑战。让我们以仅包含两轮协议的情况为例进行快速演示。
在第一轮中：
1. 证明者生成一个承诺。
2. 证明者获取该承诺和问题的公共输入，将它们拼接并进行哈希运算。其结果将作为第一个挑战：

$$challenge = hash(commitment\ ||\ public\ inputs)$$

3. 证明者计算对该挑战的响应——即一个证明。

在第二轮中：
1. 证明者生成一个新的承诺。
2. 证明者获取新的承诺以及协议中目前为止计算出的所有内容（旧承诺、证明和公共输入），将它们拼接并哈希。结果将作为新的挑战：

$$new\ challenge = hash(commitment\ ||\ proof\ ||\ new\_commitment\ ||\ public\ inputs)$$

3. 证明者计算对新挑战的响应——即一个新的证明。

此时，证明者可以将协议的整个成绩单（transcript）发送给验证者。验证者需要：
1. 通过使用哈希函数和所有有效输入，确保所有挑战都是被正确计算出来的。这是为了确证明者没有尝试用捏造的挑战来欺骗。
2. 按照之前交互式协议中的相同方式，验证所有证明的有效性。这是为了确证明者确实知道初始问题的解。

图 17-4 展示了验证者在验证零知识证明的有效性之前，先确保证明是被正确计算出来的过程。

![Figure 17-4](<./images/figure 17-4.png>)

图 17-4. Fiat-Shamir 启发式使协议变为非交互式

就是这样！得益于 Fiat-Shamir 启发式，我们现在拥有了一个非交互式零知识证明系统。由此带来的一个非常有用的“附赠”功能是：证明者现在能够生成一个任何人都可验证的有效证明。因此，我们只需要一个诚实的参与方来验证该证明，就能检测出证明者是否在尝试作弊。

### 结论？

在本节中，我们为划分问题构建了第一个非交互式零知识证明系统。现代零知识架构要复杂得多，本书显然不会解释所有的细节（尽管你可以在本章末尾找到一些非常优秀的论文以供进一步阅读）。尽管如此，我们目前讨论的内容是所有新零知识技术的基础。如果你理解了这些，你就可以跳进零知识的“兔子洞”，开始探索其背后的所有细微之处。

在下一节中，我们将介绍两种最广泛使用的构建零知识证明系统的真实框架：SNARK 和 STARK。

## SNARK 与 STARK 的对决

此前，我们成功为最初的“划分问题”创建了一个零知识证明系统。这是一个良好的开端。现在，如果我们想为完全不同的计算创建一个零知识证明系统该怎么办呢？我们能复用之前为划分问题构建的架构吗？

事实证明我们不能：承诺 $w$ 及其属性——例如 $|s[i]| = |w[i+1] - w[i]|$ ——对于划分问题过于特殊，无法应用于其他问题。然而，这并不是一个大缺点：我们可以利用从构建该系统中学到的经验来开发一种更通用的方法。这就是 SNARK 登场的地方。正如我们在“历史”部分讨论过的，SNARK 在 2011 年的 BIT+11 论文中被提出，作为一种为任意计算构建零知识证明的通用框架。仅两年后，Pinocchio 论文就实现了第一个可用于现实应用的方案。

SNARK 系统依赖于一种被称为“可信设置”（trusted setup）的密码学秘密，以此来实现非交互式的运行方式。 你可以将其视为所有密码学协议参与者共享的公共知识库：这是一种初始化阶段，你需要生成一些秘密，并利用它们计算出其他数值——即证明密钥（proving keys）和验证密钥（verification keys）——这些密钥是 SNARK 协议正确执行所必需的。

通常，可信设置是通过多方计算（multiparty computation）获得的：许多参与者各自生成不同的秘密（也称为有毒废物，toxic waste），计算出证明和验证密钥，然后删除他们最初的秘密。最后，将这些密钥合并，得到将在 SNARK 协议中使用的最终两组密钥。这种方式的主要优势在于：只要有一位心怀善意的实体删除了其“有毒废物”，就能确信任何人都无法作弊，且可信设置是以防篡改的方式生成的。 我们在第 4 章讨论 KZG 承诺时已经涵盖了这一点。

尽管 SNARK 协议运行得非常完美，但可信设置中“ $N$ 分之一”的信任假设（即假设 $N$ 个参与者中至少有一个诚实），加上创建一个极具韧性的初始“仪式”来生成最终公钥的难度，始终引发了大量讨论。这促使多位研究人员和公司开始寻找完全不需要可信设置的无须信任（trustless）零知识证明系统。此外，SNARK 系统依赖于椭圆曲线密码学（elliptic curve cryptography），这并不具备抗量子性，这是人们指出的另一个关键缺陷。

2018 年，由 Eli Ben-Sasson、Iddo Bentov、Yinon Horesh 和 Michael Riabzev 撰写的论文[《可扩展、透明且后量子安全的计算完整性》](https://oreil.ly/TCnTT)（"Scalable, Transparent, and Post-Quantum Secure Computational Integrity"）引入了一个用于构建通用零知识证明系统的新型无须信任框架：zk-STARK。STARK 代表“可扩展的（scalable）透明（transparent）知识论证”。特别地，“透明”是指其不需要可信设置这一突破性属性。它还依赖于抗碰撞哈希函数（collision-resistant hash functions）而非椭圆曲线密码学，这使其甚至具备了抗量子性。

这些优势解释了为什么现在大多数人认为 STARK 是最现代的零知识证明系统。然而，SNARK 并不是一种过时的技术。它们在某些场景下确实具有优势，主要体现在证明大小（proof size）上，这在区块链等带宽受限的环境中可能至关重要。此外，目前已经开发出了几种混合方法，试图结合两者的优点。

## zk-EVM 与 zk-VM
在对零知识证明系统的工作原理进行了技术深钻之后，我们终于可以回到以太坊，看看这项技术近年来是如何演进的。

我们已经解释了如何利用零知识证明系统来改进以太坊——即证明一个区块的 EVM 执行过程，这样全节点就不必重新执行该区块中的所有交易，即可无须信任地更新其状态。相反，他们只需验证一个零知识证明，如果证明有效，他们就知晓新状态是经过正确计算得出的。我们还看了一个为特定计算（划分问题）创建零知识证明系统的基础示例，随后介绍了 SNARK 和 STARK 框架，它们让我们可以将架构通用化，并将其应用于任何任意计算。因此，我们立刻会想到：我们能使用 SNARK 或 STARK 系统来正确证明 EVM 区块的执行吗？答案是肯定的，但我们需要做出一些选择。

在划分问题的例子中，我们必须对初始命题（即你是否能将一个整数集合分成两个和相等的子集）进行轻微转换，使其变得更易于被我们后来构建的系统证明——即我们增加了满足条件的赋值 $a$ 以及它必须满足的三个约束条件。这种转换是为了能够以数学方式处理问题所必需的，这同样适用于 SNARK 和 STARK 框架。

事实上，尽管使用 SNARK 或 STARK 框架可以零知识证明任何任意计算，但你首先需要将该计算转化为框架能够正确消化和处理的形式，这通常被称为电路（Circuit）。事实证明，这是一项非常艰巨的任务。特别是，将像 EVM 状态转换函数这样复杂的计算转化为零知识电路极易出错，而且如果出现错误或问题，调试起来也非常困难。如果电路不正确或存在漏洞，那么随后生成的零知识证明就是不可信的，因为它并不反映实际完成的计算，甚至可能为虚假陈述生成有效的零知识证明——例如，声称新的 EVM 状态是“状态1”，而正确的应该是“状态2”。

一个包含零知识证明生成系统的 EVM 实现被称为 zk-EVM。你可以在 ZKsync 的仓库中找到具体的 zk-EVM 实现。

起初，每个想要构建 ZK rollup 的项目都必须承担为 EVM 状态转换函数创建正确零知识电路的艰巨工作。这就是为什么在撰写本书时（2025年6月），Optimistic rollups 的数量远多于 ZK rollups。但得益于 zk-VM 的到来，情况正在迅速改变。zk-VM 彻底改变了构建 ZK rollup 以及更广泛的 EVM 状态转换函数零知识证明系统的视角。这个想法非常直观：与其为每种不同的计算创建自定义电路，以便随后应用 SNARK 或 STARK 框架，如果我们能创建一个可用于所有类型计算的通用电路呢？它将成为一种通用的零知识计算机，可以处理任何任意计算。这种抽象层非常强大：“一个电路统治所有”。

通过这种方式，你只需要关注你想要证明的计算逻辑，而 zk-VM 会处理生成证明的所有繁重工作。目前最著名的 zk-VM 是 [SP1](https://oreil.ly/kgVYY) 和 [RISC Zero](https://oreil.ly/z6v2l)。

图 17-5 提供了一个精简的可视化图表，捕捉了 zk-EVM 和 zk-VM 框架的核心要素。

![Figure 17-5](<./images/figure 17-5.png>)

图 17-5. zk-EVM 与 zk-VM 框架的对比

## 总结
在这最后一章中，我们探索了零知识（Zero-Knowledge）技术的基础：从 1985 年的诞生，到 BIT+11 和 Pinocchio 论文带来的突破性创新，这些研究真正将该技术带入了现实应用，特别是在区块链领域。我们以小型的“划分问题”为例，直观地理解了这些复杂系统底层是如何运作的。随后，我们研究了更为通用的方法，如 SNARK 和 STARK 框架，它们使得将标准方法论应用于任何任意计算并构建零知识证明系统成为可能。最后，我们介绍了最近的一项进展：zk-VM。得益于其单个电路即可处理任意计算的巨大优势，开发者无需再为特定计算花费时间创建定制电路，这正在迅速改写行业格局。

以太坊的未来无疑将与零知识技术交织在一起，无论是在 L2 层级还是直接在 L1 层级。最终胜出的具体方案仍是未知数；或许它将是多种不同方法的结合，以确保对漏洞或故障具有更强的韧性。唯有时间能告诉我们答案……

如果你想进一步深挖这个“兔子洞”，以下资源是极佳的选择：
* 简单的入门示例： [A simple example](https://oreil.ly/jVNdu)
* Ethan Buchman 的名篇： ["You Could Have Invented SNARKs"](https://oreil.ly/jiaOa) —— 适合想从直觉理解 SNARK 推导过程的读者。
* Maksym Petkus 的深度解析： ["Why and How zk-SNARK Works: Definitive Explanation"](https://oreil.ly/EUUzt) —— 对数学背景（多项式、配对等）最清晰的解释之一。
* RareSkills 零知识证明手册： [The RareSkills Book of Zero Knowledge](https://oreil.ly/tpHrl) —— 适合开发者的实战导向教程。



