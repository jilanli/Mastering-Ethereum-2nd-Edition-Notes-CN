# 第 16 章：以太坊的扩容

以太坊是功能最强大、使用最广泛的区块链平台之一，但正如我们一再看到的，成功往往伴随着成长的烦恼。以太坊由于过于普及，其底层网络（L1）正面临处理能力不足的困境：Gas 费用经常飙升至交易成本难以承受的地步，系统也因需要处理海量数据而变得日益沉重。尽管以太坊开发者已经推出了一系列升级，如 EIP-1559（见第 6 章）、The Merge（2022 年将共识协议从 PoW 转为 PoS 的硬分叉）以及 EIP-4844（即 proto-danksharding，本章后续将详细介绍），但 L1 的基本约束仍是阻碍大规模应用瓶颈。这些改进虽有帮助，但并不能消除对 L2 Rollups 等额外扩容方案的需求。

> [!Note]
> L2 Rollups 是一种扩容方案，它在链下处理交易，然后将摘要（如证明或数据批次）发布到以太坊的第一层（L1）。这种方式在减轻拥堵和降低费用的同时，依然依赖以太坊来保障安全性。Rollup 主要分为两类：乐观 Rollup (Optimistic Rollups)（先行假设交易有效，若有误则发起挑战）和 零知识 Rollup (Zero-Knowledge Rollups)（通过密码学证明交易的正确性）。以太坊实质上变成了一个结算层（Settlement Layer），这意味着它的核心角色转变为验证证明、确保数据可用性，并为 L2 交易提供最终的安全保障。我们将在本章的第二部分详细探讨 Rollup。

## 以太坊第一层（Layer 1）的问题

为了全面理解以太坊面临的扩容挑战，我们需要将问题拆解为四大核心矛盾：可扩展性三难困境（Scalability Trilemma）、Gas 成本与网络拥堵、状态增长与存储瓶颈，以及区块传播与 MEV（最大可提取价值）。这些问题并非以太坊所独有——其他区块链也会以不同形式遇到同样的困境——但以太坊的极高普及度放大并激化了这些矛盾。让我们深入探讨每一个问题。

### 可扩展性三难困境

与任何无需许可的区块链一样，以太坊有三个基本目标：去中心化、安全性和可扩展性。但问题在于：提高其中一个维度往往意味着要牺牲另一个维度。这就是维塔利克·布特林（Vitalik Buterin）所说的“可扩展性三难困境”。

让我们详细拆解：

#### 去中心化
去中心化使以太坊具备抗审查性和去信任化特征。任何人都可以运行节点、验证交易并参与网络，而无需获得中心化机构的许可。

#### 安全性
安全性确保以太坊能够抵御攻击。交易必须不可逆，智能合约必须不可篡改，恶意行为者不应有任何简便方法来操纵系统。

#### 可扩展性
可扩展性使网络能够每秒处理数千甚至数百万笔交易（TPS），使其具备全球规模化应用的实用性。

挑战在于，像以太坊这样的传统区块链在设计上优先考虑完全的去中心化和安全性，而以可扩展性为代价。每笔交易都由所有节点处理，这确保了正确性，但也造成了瓶颈。

为什么我们不能直接提高吞吐量？ 如果我们试图通过增大区块（以容纳更多交易）来提速，那么能够运行全节点的人就会变少，因为硬件要求会变得过于苛刻。这可能会将以太坊推向中心化——即只有少数强大的实体控制网络，这恰恰是我们试图避免的。

其他区块链（如 Solana）采取了不同的方法。它们针对速度和可扩展性进行了优化，但以去中心化为代价，要求使用更强大的硬件来运行节点。以太坊拒绝在去中心化上妥协，这使得扩容的挑战变得更加艰巨。

通过“合并（The Merge）”引入的 PoS 取代了高耗能的 PoW 系统。这不仅戏剧性地降低了以太坊的能源消耗，还减少了那些负担得起巨额采矿设施的大玩家的统治地位。虽然质押（Staking）引入了新的中心化风险，但它仍是迈向更易触达和更高效网络的一步。然而，PoS 也带来了新挑战，例如大型质押池带来的中心化风险。流动性质押（Liquid Staking）方案有助于保持已质押 ETH 的流动性，但它们也将控制权集中在了少数几个平台手中。寻找正确的平衡点仍是一项正在进行的工作。

### Gas 成本与网络拥堵

对于以太坊用户来说，最令人沮丧的体验之一莫过于高昂的 Gas 费用，且交易成本会随网络需求剧烈波动。这是如何发生的？为什么在高峰时期费用会变得如此昂贵？

以太坊交易需要 Gas，这是一个衡量执行转账或智能合约交互等操作所需计算量的单位。操作越复杂，所需的 Gas 就越多。每个区块能容纳的 Gas 总量是有限的，这意味着用户必须竞争有限的区块空间。当需求旺盛时，用户会相互竞价，从而推高费用。

我们曾见证过这种竞价机制引发的戏剧性场面：

#### CryptoKitties 狂热 (2017年)

这是对以太坊极限的第一次真正考验。一款允许用户繁殖和交易数字猫的简单游戏严重堵塞了网络，导致交易速度降至龟速，Gas 费用飙升。

#### DeFi 之夏 (2020年)

Uniswap 和 Compound 等 DeFi 应用的爆发为以太坊带来了海量活动。交易者争先恐后地进行操作，有时为了在内存池（Mempool）中获得优先权而支付数百美元的 Gas 费。

#### NFT 热潮 (2021年)

NFT 的发售演变成了“Gas 战争”，用户为了抢在他人之前铸造新的数字收藏品不惜支付数千美元。即便花费了巨额 Gas 费，部分交易最终仍以失败告终。

以太坊的第一层（L1）最初并非为了高效处理如此高强度的需求而设计。然而，2021 年引入的 EIP-1559 通过可变区块大小和全新的 Gas 定价机制改变了费用运作方式，减少了网络高活跃期费用的剧烈波动。随着 L2 方案的普及，以太坊得以卸下大部分计算负担，进一步降低了 Gas 费。最近，EIP-4844 (proto-danksharding) 的实施显著降低了费用（尤其是 L2 Rollups 的费用），使普通用户更能负担得起以太坊交易。尽管有了这些改进，以太坊的交易成本仍高于大多数其他区块链（见图 16-1）。

![Figure 16-1](<./images/figure 16-1.png>)

图 16-1. 各区块链 Gas 成本对比

### 状态增长与存储问题

以太坊不仅仅用于交易，它还是一个全球状态机，持续跟踪账户余额、智能合约数据、DeFi 头寸、NFT 以及其他链上活动。与可以存档或删除旧记录的传统数据库不同，以太坊的设计初衷是保留其完整历史，以确保透明性和可验证性。问题在于：随着以太坊的发展，它需要存储的数据越来越多，这种存储负担也变得越来越沉重。

目前，以太坊的“状态”（本质上是所有活跃账户、合约余额和存储插槽的集合）正以惊人的速度增长。每一个新合约都会增加状态，每一次交易都会修改状态。在验证网络完整性方面发挥关键作用的“全节点”，必须存储并不断更新这些数据。随着状态的增长，个人在没有昂贵硬件的情况下运行全节点变得越来越困难，这引发了对去中心化的担忧。

存档节点（Archival Nodes）面临着更大的挑战。这些节点不仅存储当前状态，还存储以太坊的整个历史记录，包括过去的每一笔交易和合约执行。这些数据的体量已达到 TB 级，需要巨大的存储容量和带宽。能够运行此类节点的人数正在萎缩，这让人不禁担忧未来将由谁来保存以太坊的长期历史。

在以太坊 PoS 系统中负责提议和见证区块的验证者（Validators）同样感受到了状态增长的压力。为了高效验证交易，他们需要快速访问最新的区块链状态。但随着状态的扩展，访问和处理这些信息变得越来越慢且昂贵。如果这种趋势不加抑制地持续下去，我们可能会面临这样一种环境：只有拥有高端硬件的人才能参与验证，从而将以太坊推向中心化。

以太坊开发者已经探索了遏制“状态膨胀”的方案，包括历史过期（History Expiry）和状态租金（State Rent），我们将在本章稍后的“L1 扩容”部分详细讨论。

客户端多样性也有所帮助。虽然 Geth 历史上一直是主导的以太坊客户端（见图 16-2），但像 Nethermind、Erigon 和 Besu 这样的替代方案引入了提高存储效率的优化。例如，Erigon 专门研究如何更高效地处理历史数据，从而减轻了全节点的负担。

![Figure 16-2](<./images/figure 16-2.png>)

图 16-2. 以太坊客户端分布

### 区块传播与 MEV

即便以太坊能够处理更高的交易吞吐量，仍存在另一个根本性的瓶颈：新区块在网络中传播所需的时间。当一名验证者产出一个新区块时，该区块必须立即广播给全球成千上万个其他节点。区块体积越大，传播所需的时间就越长。而传播时间越长，网络产生分歧甚至出现临时分叉（即网络的不同部分在瞬间发生偏离）的概率就越高。

虽然 PoS 机制有助于降低这些风险，但区块传播延迟仍会影响性能。客户端开发团队一直在致力于网络优化以提升速度，随着以太坊的扩容，这将是一个我们需要持续改进的挑战。

在表象之下，还潜伏着另一个问题：MEV。尽管以太坊已经转型为 PoS，但“矿工可提取价值”这个名称被沿用了下来。如今，更准确的称呼应是最大可提取价值（Maximal Extractable Value），指验证者和搜索者通过策略性地对区块内的交易进行重排、包含或排除而获得的利润。

MEV 的产生是因为交易并不总是按照提交顺序被处理。相反，验证者可以根据自身的盈利动机来优先处理某些交易。这为精明的参与者创造了榨取价值的机会，但往往以损害普通用户的利益为代价。高频交易机器人会扫描内存池（Mempool）（以太坊等待进入区块的交易“候车室”），寻找获利机会。例如，如果有人在 Uniswap 等去中心化交易所提交了一笔大额交易，机器人就可以抢在他们之前买入资产，然后再以更高的价格卖回给用户。这被称为三明治攻击（Sandwich Attack），是抢跑（Front-running）的一种形式，也是 MEV 最臭名昭著的表现之一。

一种已经运行多年的缓解方案是 MEV-Boost，这是由 Flashbots 开发的一套协议，旨在让 MEV 变得更加民主和透明。然而，长期的解决方案是更彻底的底层重新设计：原生提议者-构建者分离（Native PBS）。我们将在下一节详细探讨这些解决方案。

> [!Note]
> MEV 在大多数 L2 链中基本不复存在，因为它们通常依赖于中心化交易定序器（Sequencers）。单一的中心化定序器通常按照收到交易的先后顺序进行处理，从而消除了重新排序交易或抢跑获利的机会。虽然这种中心化方法显著减少了 MEV，但确实在去中心化和抗审查性方面引入了潜在的权衡。未来的 L2 发展旨在通过引入去中心化定序机制来平衡这些权衡。

## 解决方案

我们正在采取哪些措施来克服以太坊的扩容挑战？虽然没有单一且简单的解决方法，但开发者们正积极推进多项改进，旨在让网络更快、更便宜，并为大规模应用做好准备。让我们近距离了解一下他们正在探索的主要策略。

### 扩展第一层（Scaling the L1）

扩展以太坊的底层（即第一层，L1）是自诞生之日起我们就面临的最艰巨挑战之一。现实情况是，没有任何单一的修复手段能解决所有问题；扩容并不是一个可以随意开启的二元开关，而是一个长期的过程：它是一系列优化的组合，旨在牺牲去中心化或安全性的前提下，逐步提高以太坊的效率。虽然 L2 Rollups 是我们处理绝大多数交易的最佳选择，但改进以太坊底层依然至关重要。如果我们能提高 L1 的吞吐量和效率，Rollup 将变得更加强大，Gas 费用会进一步下降，以太坊也能在不诉诸中心化的情况下保持竞争力。让我们来看看改进以太坊底层的几种核心方式。

#### 提高 Gas 上限（Raising the Gas Limit）

以太坊区块受限的不是交易数量，而是每个区块能容纳的 Gas 总量，即 Gas 上限（Gas Limit）。我们可以将其看作一种“预算”。每笔交易根据其复杂程度消耗 Gas，而区块中可用的 Gas 则由 EIP-1559 机制定义。提高 Gas 上限意味着每个区块可以容纳更多交易，从而有效地增加以太坊的吞吐量。

但这绝非简单地调高数值那么简单。更大的区块在网络中传播所需的时间更长，这会使以太坊更容易受到链分裂（Chain Splits）的影响。同时，它们还会提高全节点的硬件门槛，将我们推向中心化。因此，Gas 上限的提高必须循序渐进且极其谨慎，在提升吞吐量与维护网络健康之间寻找平衡（见图 16-3）。

![Figure 16-3](<./images/figure 16-3.png>)

图 16-3. 以太坊 Gas 上限历史变更图

#### 以太坊并行执行的未来

由于采用共享状态模型，以太坊目前按顺序处理交易。这确保了安全性和一致性，但由于交易无法并行执行，限制了可扩展性。相比之下，一些较新的区块链（如 Solana 和 Aptos）采用了并行执行，但它们依赖于更中心化的架构，并要求验证者使用高性能硬件。

以太坊面临的挑战在于，交易经常会与相同的状态发生交互——例如，两笔 DeFi 交易同时修改同一个流动性池。如果没有强大的依赖管理系统，重排交易顺序可能会破坏智能合约逻辑。另一个复杂性在于，全节点必须验证所有交易，引入并行执行需要在多个线程之间进行精密的同步。

以太坊研究人员正在积极探索在保持去中心化的前提下引入部分并行执行的方案。一种方法是无状态执行（Stateless Execution），它能减少对全节点存储的依赖，使交易处理更加高效。另一种是乐观并发（Optimistic Concurrency），即假设交易之间是相互独立的，仅在发生冲突时才进行回滚。我们将在本章的第二部分详细解释这些概念。

在兼容 EVM 的链中已经出现了几种并行 EVM 的实验性实现，包括 Monad、Polygon PoS 和 Shardeum。例如，Monad 实现了乐观并行执行模型，其吞吐量可超过 10,000 TPS。Polygon PoS 通过其 Block-STM 方案实现了 1.6 倍的 Gas 吞吐量提升，允许对交易进行部分并行化。这些进展提供了宝贵的见解，但以太坊必须在实现并行的同时维护去中心化，这一平衡点仍是一个核心挑战。

最近的研究表明，大约 64.85% 的以太坊交易可以并行化，这突显了性能提升的巨大潜力。然而，截至 2025 年 3 月，以太坊主网尚无集成并行执行的具体计划。关于通过“区块末端虚拟交易”实现 EVM 并行的讨论仍在进行中，但以太坊执行模型的复杂性使得实施过程极具挑战。以太坊扩容路线图包括对交易依赖解析、替代执行模型以及逐步提升 EVM 效率的持续研究。

#### 状态增长与过期

以太坊的状态（包含所有账户余额、智能合约存储及其他链上数据的集合）正在持续膨胀。每一个新合约都会增加数据，且一旦数据写入以太坊状态，它就会永远留存。这虽有利于去中心化和可验证性，但对可扩展性却是灾难性的。全节点必须存储并处理所有这些数据，随着状态体量的增大，运行节点的成本也随之攀升。

目前，全节点的以太坊状态大小约为 1.2 TB，而存储完整历史状态和交易数据的存档节点（Archival Nodes）则需要超过 21 TB 的存储空间。如此巨大的数据脚印使得个人运行存档节点变得愈发困难，导致这一角色集中在少数资金雄厚的实体手中。值得一提的是，Erigon 和 Reth 执行客户端经过优化，所需的存储空间显著减少——这两者运行存档节点仅需约 2 TB。

人们经常混淆“状态过期”与“历史过期”，但它们解决的是不同的问题。**状态过期（State Expiry）**旨在通过要求智能合约定期为其占用的存储支付“租金”，来缩减以太坊活跃维护的状态规模。如果某个合约未付租金，它将变得不可访问，直到有人明确出资将其恢复。这将显著减缓状态增长，并降低全节点的运行负担。

相比之下，历史过期（History Expiry）处理的是海量的历史交易数据。以太坊可以对旧数据进行“修剪（Pruning）”，将其转交给外部存储方案，而不是强制每个节点存储所有历史交易。这不会影响实时状态，但会使历史查询更加依赖第三方数据提供商。这两种方法都存在权衡，相关研究仍在进行中，以寻找效率与可访问性之间的最佳平衡点。

如需进一步探索该主题，建议研究涵盖历史过期的 EIP-4444。至于状态过期，目前仍处于研究阶段，尚无明确方案，但你可以在以太坊路线图（The Purge 部分）中找到更多信息。

#### 提议者-构建者分离（Proposer-Builder Separation, PBS）

即使在转向 PoS 之后，MEV 依然是以太坊中一个顽固的问题。验证者和专业的搜索者（Searchers）通过交易重排、抢跑及其他策略来榨取利润，而这往往以牺牲普通用户的利益为代价。这不仅是一个经济问题，它还会影响网络健康，加剧拥堵并导致 Gas 费用变得不可预测。

PBS 是缓解 MEV 问题最受期待的解决方案之一。目前，验证者既负责“提议”区块也负责“构建”区块，这意味着他们拥有对交易排序的完全控制权。PBS 通过拆分这两个角色改变了现状：验证者仍然负责提议区块，但实际的区块构造工作则通过竞争性拍卖外包给专业的构建者（Builders）。这消除了验证者直接参与 MEV 榨取的动力，并使交易包含过程更加透明。

PBS 已经以 MEV-Boost 的形式进行了实战测试，该协议允许验证者将区块构建权外包给最高出价者。然而，必须理解的是，MEV-Boost 和 PBS 并不会消除 MEV；它们只是让 MEV 变得更加透明和公平。MEV 将继续存在，因为驱动套利、抢跑和三明治攻击的底层动机并不会消失。PBS 的意义在于，它确保了 MEV 的捕获过程是开放、公平且具有竞争性的，而不是让少数内部人士通过不透明的策略获利。长远来看，还需要将订单流拍卖（Order-flow Auctions）、加密内存池（Encrypted Mempools）等其他 MEV 缓解技术与 PBS 结合，以进一步减少其负面影响。

### Rollups（层级汇总）
以太坊长期面临可扩展性、交易吞吐量（以 TPS 衡量）及高昂费用的挑战。为了解决这些问题，Rollup 的概念应运而生。

Rollup 是一种在专门的 L2（第二层）“链下”执行交易，然后将聚合后的数据或证明发布回 L1（第一层）区块链的机制。由于繁重的计算和状态更新是在 L1 之外完成的，区块链避开了通常的吞吐量瓶颈，从而提升了交易速度并降低了费用。实际上，Rollup 自身的执行环境更高效地处理签名检查、合约执行和状态转换，而 L1 则作为权威的“结算层”存在。

Rollup 旨在尽可能保留 L1 的安全性。其安全目标包括：确保数据可用性（Data Availability）、验证状态转换的正确性以及提供抗审查性。数据可用性要求所有交易和状态信息都必须是可获取的，以便在发生争议时，参与者可以独立验证链的状态，或依靠发布在（或由其担保的）L1 上的数据安全地提取资金。状态转换完整性通过有效性证明（如零知识证明）或欺诈证明，确保 L2 上的变更符合网络规则。最后，抗审查性保证了没有任何单一实体或少数参与者能无限期地封锁或扣留用户交易。

> [!Note]
> 数据可用性与有效性是安全 Rollup 实现的核心组件，确保恶意行为者无法伪造交易、窃取资金或凭空增加余额。数据有效性通常依赖于两种主要方法：
> 零知识证明 (Zero-Knowledge Proofs)：每一批 L2 交易都附带一个加密证明，证明执行过程正确无误。当证明提交至 L1 时，智能合约会在接受新状态根之前验证其正确性。
> 欺诈证明 (Fraud Proofs)：基于“乐观假设”，即 L2 运营者向 L1 发布新状态，任何人都可以通过提供违规证据来挑战这些提交。如果欺诈证明被采纳，无效批次将被撤回，恶意行为者将面临惩罚。
> 
> 除了有效性，数据可用性确保如果 L2 运营者失踪或行为不端，用户始终可以重构整条链。实现这一点有不同方法：一些系统将所有交易数据直接存储在 L1（通常作为以太坊的 calldata，或现在更常见的 blobs），使其透明地记录在区块链日志中。其他设计则依赖链下数据可用性层、专门的网络或提供经济激励的外部存储方案。混合方法可能会结合两者：将关键信息放在链上，而将次要数据存储在链下。

Rollup 依赖于部署在 L1 上的专用智能合约，该合约负责维护所有 L2 账户的“规范状态（Canonical State）”。合约存储着一个代表当前 L2 状态的根（通常是默克尔根 Merkle Root），接收由指定角色（有时称为定序器 Sequencers、聚合器 Aggregators 或运营者 Operators）提交的新交易批次，并验证这些批次的有效性。根据 Rollup 类型，合约会校验零知识证明或处理欺诈证明，以确保状态更新合法。一旦检测到违规行为（例如欺诈证明挑战成功），合约可以回滚该无效批次。

理论上，任何满足 Rollup 要求（如质押保证金）的人都可以向智能合约提交 L2 交易的状态更新。但在现实中并非总是如此。事实上，截至目前，大多数交易量和锁仓量（TVL）最高的 Rollup 在定序器层面仍是中心化的。虽然部分 Rollup 已实现去中心化，但对大多数项目而言，这仍是一个终极目标。
每次状态更新包含：前一个状态根（以显示连续性）、新提议的状态根（反映提交交易后的结果），以及压缩后的交易数据或其引用。如果满足 Rollup 规则（且在乐观 Rollup 中未出现有效挑战），合约就会将其存储的状态根更新为新根，使其成为规范的 L2 状态。

不同的 Rollup 处理欺诈或无效状态更新的方式截然不同：
乐观 Rollup (Optimistic Rollups)：默认假设新状态更新是正确的，但提供一个挑战期（通常持续数天），允许任何人提交欺诈证明。如果证明被核实，无效状态将被回滚，且恶意提交者的质押金会被罚没（Slashing）。
零知识 Rollup (Zero-Knowledge Rollups)：要求每个新状态根必须随附一个零知识证明。由于该证明是在链上即时验证的，主链能立刻判断更新是否有效；只要证明正确，就不需要漫长的挑战期。

#### Rollup 的发展阶段（Rollup Stages）

在早期阶段，大多数 Rollup 都会保留部分中心化控制权，这通常被称为“辅助轮（Training Wheels）”。它们允许运营者在出现漏洞或需要关键更新时迅速介入。尽管这对于新系统来说非常实用，但真正的去中心化要求这些“辅助轮”必须逐步拆除。

为了规划这一过渡过程，业界在维塔利克·布特林（Vitalik Buterin）最初提出的里程碑基础上，建立了一个将 Rollup 分为三个成熟阶段的框架。每个阶段都标志着有多少权力仍掌握在中心化手中，以及该 Rollup 距离完全继承以太坊底层安全性的目标还有多远。

在 阶段 0 (Stage 0)，一个项目虽然自称为 Rollup，但仍处于运营者的严密控制下。它会向 L1 提交状态根并提供 L1 上的数据可用性，确保在出现问题时能够重构 L2 状态。然而，此时系统的“证明机制”（欺诈证明或有效性证明）可能尚未由链上智能合约完全强制执行；如果发生错误，主要依靠运营者的干预作为兜底。本质上，阶段 0 确保了 Rollup 的基本要素——链上数据、状态根和面向用户的节点软件——已经到位，但治理仍保持中心化。

> [!Note]
> 该三阶段框架的要求可能会随时间而变化。例如，截至本文撰写时（2025 年 2 月），Arbitrum 是一个阶段 1 (Stage 1) Rollup；但根据新的要求，如果它未能及时完成网络升级，可能会降级为阶段 0。

阶段 1 (Stage 1) Rollup 必须拥有完善的证明系统（乐观 Rollup 的欺诈证明或零知识 Rollup 的有效性证明），并且必须至少有 5 个外部参与者 能够提交这些证明。用户还应当能够在无需运营者配合的情况下撤出（Exit）系统，从而保障其免受审查。另一个标准是：如果用户不同意提议的系统升级，必须拥有至少 7 天的退出窗口期；尽管在出现严重漏洞时，“安全委员会（Security Council）”仍可迅速介入。该委员会必须通过多签（Multisig）形式组成，要求 8 个或更多签署人中至少 50% 同意 $^1$ ，且其中一半成员必须是 Rollup 主要组织之外的外部人士。虽然该委员会可以修复漏洞或撤销恶意交易，但仍存在潜在的单点故障。

$^1$ 该要求最近有所改动。本章将不再详细分析具体变化，更多信息请参阅 Luca Donno 的 Medium 文章。

阶段 2 (Stage 2) 标志着 Rollup 真正实现了去中心化，依赖于无需许可的证明和稳健的用户保护 $^2$。其欺诈或有效性证明系统必须向所有人开放，不得设有白名单。如果引入治理提案或升级，用户必须拥有至少 30 天的退出时间，以确保他们不会被强迫接受变更。安全委员会的角色被严格限制在处理链上的“稳健性错误”（例如提交了相互矛盾的证明），而非拥有广泛的治理权或裁量权。因此，在这一最终阶段，人为干预被限制在极小范围内，Rollup 主要由智能合约和社区共识治理，紧密契合以太坊“最小化信任”的核心理念。

$^2$ 阶段 2 (Stage 2) 并不意味着更好的用户体验（UX）或更高的采用率；它仅仅代表更高程度的去中心化。

我们要向所有参与开发和更新这一框架的人员，以及所有参与分析并公开 Rollup 阶段信息的人员表示感谢；你们的贡献极具价值，且正是行业所急需的。

#### 乐观 Rollups (Optimistic Rollups)

乐观 Rollup 依赖于欺诈证明 (Fraud Proofs)。运营者在发布状态根到 L1 时，预先假设这些数据是有效的。然而，观察者（Observers）保留对他们认为存在欺诈的批次进行挑战的权利。如果挑战被证实正确，无效批次将被回滚，且运营者会受到惩罚。由于有效性并非即时确认，用户通常必须等待一个挑战窗口期（有时长达一周或更久），才能放心地提取资金或实现最终确认（Finality）。

这种设计虽然导致了较长的提现时间，但由于无需构建复杂的零知识证明电路，它能更轻松地兼容 EVM，且证明复杂度较低，简化了系统运行的某些环节。尽管如此，延迟提现会影响用户体验；此外，如果运营者的保证金少于锁仓总价值（TVL），还可能存在经济攻击的风险。乐观 Rollups 的典型案例包括 Arbitrum、Optimism、Base 以及其他受“Optimistic Ethereum”模型启发的项目。


#### 零知识 Rollups (ZK Rollups)

ZK Rollup 基于有效性证明 (Validity-Proof) 机制运行。当服务商在 L2 汇总交易时，会生成加密证明（通常是 SNARKs 或 STARKs），用以证明状态转换的正确性。这些证明会在链上进行验证，由于无需漫长的挑战窗口期，它能提供近乎即时的最终确认性（Finality）。

用户可以从快速提现中获益，因为无需等待确认期来验证合法性。其高度安全性源于对证明的直接验证，减少了对观察者（Watchers）或巨额运营者保证金的依赖。在链上验证一个证明通常比逐一处理每笔交易更高效。然而，为通用型 EVM 计算实现零知识证明在计算上非常昂贵，可能需要专门的硬件支持。

##### 零知识证明的风险

现实情况是，最前沿的密码学技术也蕴含着风险。以 Zcash 为例，Zcash 使用了论文《Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture》中提出的部分实现方式，该论文描述了 Zcash 最初启动时所采用的 zk-SNARK 构造。2018 年，即在该论文发表并经过数十次同行评审数年后，当时受雇于 Zcash 的密码学家 Ariel Gabizon 发现了一个细微的密码学缺陷。该缺陷会导致假币制造漏洞——本质上是一种双花攻击（Double-spend Attack）。虽然该漏洞在 Zcash 的 Sapling 升级中得到了修复，且目前看来似乎未被任何人利用，但它在这一篇广为人知且被频繁引用的论文中潜伏了多年才被察觉。在本章中，我们将零知识证明称为“高安全性”和“值得信赖”的。这在通常情况下是正确的，但如果这种假设从未受到质疑，那将是非常危险的。此外，某些零知识系统（尤其是常见的 SNARKs）还需要可信设置（Trusted Setup） $^3$ 来生成初始参数，这本身也带有安全考量。领先的 ZK-rollup 项目包括 ZKsync、Starknet、Scroll 和 Aztec。其中，Aztec 还以“ZK-ZK-rollup”为标签整合了隐私功能。

$^3$ 详见第 4 章的讨论。

ZK Rollups 最初非常适合处理代币转账或兑换等简单任务，但在处理更复杂的功能时却显得力不从心。随着 zk-EVM 的出现，这一局面得到了改变。zk-EVM 旨在链下模拟完整的 EVM（以太坊虚拟机）环境。通过为包括 EVM 字节码执行在内的图灵完备计算生成证明，zk-EVM 扩展了 ZK Rollup 的应用范围，使各类去中心化应用（DApps）都能同时受益于高可扩展性和零知识级的安全性。

各个项目在实现 zk-EVM 功能时选择了不同的路径：
* 转译器（Transpiler）法：将 Solidity（或其他 EVM 高级语言）转换为对电路更友好的语言，例如 Cairo（由 StarkWare 使用）。
* 字节码直接解释法：直接逐个操作码（Opcode）地解释标准 EVM 字节码，构建反映每条指令的电路。
* 混合或多类型方案：对 EVM 的某些部分（如数据结构或哈希算法）进行调整，使其更易于证明，同时尽量保持与以太坊近乎完全的兼容性。

关于 zk-EVM 的更多内容，本章将不再展开，我们将在第 17 章进行深入探讨。

### 其他类型的扩容方案

乐观 Rollup 和 ZK Rollup 并非唯一的扩容方案；它们是目前被广泛采用的两种主流方案，但未来格局可能会发生变化。我们将对其余的扩容方案进行分析：对于那些较为陈旧、目前再次流行可能性较低的方案，我们将简要带过；而对于那些新兴且极具前景的方案，我们将进行深入探讨。

#### Validiums

Validium 不在以太坊上存储交易数据。相反，它们仅向以太坊发布用于验证 L2 链状态的证明，如图 16-4 所示。本质上，Validium 是一种采用了替代性数据可用性方案（如 Celestia、Avail 或 EigenDA）的 Rollup。

![Figure 16-4](<./images/figure 16-4.png>)

图 16-4. Validium 架构图

作为一种 L2 方案，Validium 无需支付在以太坊上存储数据所产生的高额 Gas 费用。这种方法比 Rollup 更具成本效益，意味着用户的 Gas 费要低得多。然而，Validium 通常被认为安全性略低于其他 Rollup，因为它们使用数据可用性委员会（DAC）或替代性数据可用性方案将交易数据存储在以太坊之外。

#### 侧链 (Sidechains)

侧链是与另一个区块链（称为主链）并行运行的区块链网络。通常，侧链通过双向桥（Two-way Bridge）与主链连接，该桥允许在两个网络之间转移资产，甚至可以传输任意数据，如合约状态、默克尔证明（Merkle Proofs）以及特定交易的结果。

大多数侧链拥有独立于主链的共识机制和验证者集。这使得侧链能够独立完成交易的结算与最终确认，而不必依赖另一个区块链。然而，这也意味着跨链至侧链的资金安全性完全取决于侧链验证者是否存在足够强大的加密经济激励，以遏制其恶意行为。

#### Based Rollups（主网排序 Rollup）

Based Rollup 依赖于 L1 区块链原生的排序（Sequencing）能力。这种设计实现了无缝集成，能够充分利用 L1 的去中心化、活跃度（Liveness）以及安全属性。

与传统 Rollup 相比，Based Rollup 采用了一种更简单的排序方法。大多数 Rollup 会实现自己的定序器（Sequencer），而 Based Rollup 则直接调用底层 L1 的定序器。本质上，主要的区别在于：L1 验证者直接担任 Rollup 的定序器，而不是像乐观 Rollup 那样使用外部定序器。

其共识层、数据可用性层和结算层完全复用以太坊。Rollup 内部唯一的组件是执行层，负责执行交易并更新状态。这种设计允许 L1 区块提议者直接与 L2 区块构建者及搜索者（Searchers）合作，将下一个 Rollup 区块纳入 L1 区块中。由于 Based 排序完全依赖于现有的以太坊验证体系，它不依赖任何外部共识。

> [!Note] Based Rollup 可能是目前最有前景的解决方案，其使用率甚至可能超过乐观 Rollup。这主要是因为其最终确认性（Finality）与以太坊本身一致，不同的 Based Rollup 之间可以实现原子交易（Atomic Transactions），而无需等待挑战窗口。例如，DeFi 流动性可以在不同的 Based Rollup 之间实现无缝聚合。在此之前，这被认为只有 ZK Rollup 才能做到。

#### Booster Rollups（增强型 Rollup）

Booster Rollup 处理交易的方式如同直接在 L1 上执行一般，赋予了它们对 L1 状态（State）的完全访问权；与此同时，它们又保持着各自独立的存储空间。通过这种方式，执行与存储都在 L2 层面实现了扩展，而 L1 框架则充当共享基础。换个角度来看，每个 L2 都是 L1 的镜像，通过对交易执行和存储进行分片，实际上为所有部署在 L1 上的应用增加了新的区块空间。

如果以太坊的未来需要成百上千个 Rollup 来应对极高的可扩展性需求，那么让每个 Rollup 都作为拥有独立规则和合约的孤立链运行，可能并非理想方案。因为开发者会发现自己不得不将代码重复部署到每一个 Rollup 上。

相反，Booster Rollup 直接为任何运行在 L1 上的去中心化应用（DApp）增加额外的区块空间。推出一个 Booster Rollup 可以被形象地理解为给电脑增加额外的 CPU 核心或硬盘空间。只要一个应用程序知道如何利用“多线程”（在区块链语境下即“多 Rollup”），它就可以自动利用这些扩展后的容量。开发者只需考虑如何最有效地利用这一额外环境即可。

#### Native Rollups（原生 Rollup）

Native Rollup 提案引入了 EXECUTE 预编译合约（Precompile），旨在直接作为 Rollup 状态转换的验证器；通过消除对复杂基础设施（如欺诈证明博弈、SNARK 电路和安全委员会）的需求，该提案极大地简化了等效 EVM（EVM-equivalent）Rollup 的开发。借助 EXECUTE，你只需几行 Solidity 代码即可部署精简的原生（Native）且基于主网排序（Based）的 Rollup。

由于这种新型预编译合约与“EVM 中的 EVM（EVM in EVM）”构思高度平行，它将通过以太坊常规的硬分叉流程进行升级，并受社会共识治理。这种一致性保证了 EVM 的任何更新都会自动适用于该预编译合约，因此 Rollup 无需安全委员会或多签等治理结构即可继承以太坊的验证规则，从而最终提升终端用户的安全性。

EXECUTE 预编译合约负责验证 EVM 状态转换，允许 Rollup 在应用层利用以太坊的原生基础设施。它通过 pre_state_root（前状态根）、post_state_root（后状态根）、trace（执行轨迹）和 gas_used（Gas 消耗量）等输入来检查 EVM 状态转换，同时采用类似 EIP-1559 的机制进行 Gas 定价。为了确保正确性，验证者可以根据每个 Rollup 在扩展性与复杂性之间的权衡，选择依赖重新执行（Re-execution）或 SNARK 证明。这种设计结合了 Based Rollup 方法（即定序和证明系统均直接在以太坊下运行），简化了“去信任化 Rollup（Trustless Rollups）”的创建。

### Danksharding

Danksharding 是以太坊最新的分片方案，相较于早期的设计，它在架构上进行了显著的简化。

> [!Note]
> 鉴于这是我们首次提到“分片（Sharding）”，有必要简要介绍一下这一概念。请记住，这是一个可以深入研究的课题。虽然它超出了本书的讨论范围，但仍是一个非常有趣的话题。 分片的基本概念是将网络分割成不同的部分（即分片），使每个分片能够处理交易的一个子集，从而提升整体性能并降低成本。 这一方案已被其他区块链以不同形式实现。在以太坊中，我们永远不会真正实现几年前构想的那种“纯粹分片（Pure Sharding）”，因为已经没有必要了。以太坊的路线图已经转向了“以 L2 为中心（L2-centric）”的 L1 扩容方向。

以太坊最近的分片提案（包括 Danksharding 和 Proto-Danksharding）与大多数其他分片方案的一个关键区别在于以太坊的以 Rollup 为中心的策略。以太坊分片并不直接扩大交易处理容量，而是专注于为大型数据“Blob”提供更多空间，而核心协议本身并不会解释这些数据。（关于这些 Blob，我们将在后续章节中详细探讨。）验证这些数据 Blob 的一个重要要求是确保它们保持“可访问性”——即可以从网络中检索。随后，L2 Rollup 协议将利用这些数据 Blob 来实现高吞吐量的交易，如图 16-5 所示。

![Figure 16-5](<./images/figure 16-5.png>)

图 16-5. Danksharding 架构图

Rollup 将执行后的交易存储在数据 Blob 中，并生成一个加密“承诺（Commitment）” $^4$ 用于验证。为了创建这一承诺，它们使用多项式函数对数据进行编码。随后，可以对该多项式的特定点进行求值。

$^4$ 多项式承诺就像是为一个多项式（一个数学表达式，例如 $f(x) = 2x - 1$）制作的一个简短且安全的“摘要”，它允许你在不泄露整个多项式的情况下，证明其中的特定数值。想象一下，你写下了一个秘密公式并将其锁在保险箱里。稍后，有人问：“如果我们将 $x = 10$ 代入，结果是多少？”在不打开保险箱或向他们展示完整公式的情况下，你可以快速且轻松地提供证明，证实正确答案是某个特定的数字。多项式承诺在数学上实现的正功能：它们让你能够安全且高效地证明大型数学数据集内特定点（例如 $x = 10$）的准确性，而无需暴露所有细节。关于多项式承诺的更详细解释，请参阅第 4 章。

例如，考虑一个简单的多项式函数 $f(x) = 2x - 1$。在 $x = 1, 2, 3$ 点对该函数求值，得到的值分别为 $1, 3, 5$。证明者独立地将相同的多项式应用于原始数据，并检查这些点的值。如果底层数据发生哪怕极其微小的变化，多项式（以及随之而来的求值结果）将不再匹配，从而向参与者发出数据不一致的警报。

当 Rollup 在 Blob 中发布数据时，还会同步在链上提供一个承诺（Commitment）。该承诺的创建过程是将数据拟合成一个多项式，并根据 KZG 仪式（详见第 4 章）期间产生的随机数所确定的特定点，对该多项式进行求值。证明者会独立地在这些相同的点上对多项式求值。如果其求值结果与承诺值匹配，则确认数据准确无误。在实际应用中，这些承诺及其证明更为复杂，因为它们使用了加密方法进行加固以确保完整性。

Danksharding 的主要进展是引入了统一费用市场（Merged Fee Market），旨在将 Gas 费用市场与 Blob 费用市场结合。Danksharding 不再设立多个拥有各自区块和提议者的分片，而是指定一个单一的提议者（Proposer）为每个 Slot（时隙）选择所有的交易和数据。

为了防止这种方法对验证者提出过高的硬件要求，引入了 PBS（提议者-构建者分离）机制。在 PBS 中，专业的“区块构建者（Block Builders）”通过竞价来争夺组装该 Slot 内容的权利，而提议者只需挑选出价最高且有效的区块头。只有区块构建者才必须处理完整的区块，甚至这一步骤也可以通过专门的预言机协议进一步去中心化。与此同时，验证者和用户可以依靠 DAS（数据可用性采样）来验证区块——请记住，区块的大大部分内容现在仅仅是数据。

> [!Note]
> Danksharding 和 Proto-danksharding 这两个术语分别取自帮助塑造这种分片模式的两位以太坊基金会核心人物的名字。Dank 代表 Dankrad Feist，Proto 代表 Protolambda（即 Diederik Loerakker）。两人均为研究员：在本书写作时，Feist 就职于以太坊基金会，而 Loerakker 就职于 OP Labs。

### Proto-Danksharding
Proto-Danksharding（也称为 EIP-4844）提议实现完整 Danksharding 所需的大部分基础逻辑和基础设施，例如交易格式和验证规则，但尚未引入实际的 DAS（数据可用性采样） $^5$。在 Proto-Danksharding 阶段，验证者和用户仍然需要直接验证所有数据 Blob 的完整可用性。

$^5$ 数据可用性采样是一种无需下载区块全部数据即可验证数据可用性的机制。

Proto-Danksharding 引入的核心创新是一种新型交易类型，称为携带 Blob 的交易（Blob-carrying Transaction）。这些交易（我们在第 6 章中已经分析过）的功能与常规交易类似，但包含一个名为 Blob 的额外数据组件。Blob 的体积相对较大（约 125 KB），且价格比同等大小的 Calldata $^6$ 便宜得多。然而，EVM 无法直接访问 Blob 数据；EVM 只能访问指向该 Blob 的加密承诺。此外，这些 Blob 中的数据会在固定期限后自动删除（在本书撰写时，该期限设置为 4,096 个 Epoch，约 18 天）。

$^6$ 用于存储在 EVM 外部调用期间传递的函数参数的原始数据。

由于验证者和客户端目前仍必须下载每个 Blob 的完整内容，Proto-Danksharding 将数据带宽限制在每 Slot（时隙）约 1 MB 左右。尽管存在这一限制，Proto-Danksharding 仍然提供了巨大的可扩展性优势，因为 Blob 数据的成本不会直接与标准以太坊交易的 Gas 成本竞争。

在阅读完这些内容后，你可能会产生一些疑问。
#### 为什么在 18 天后删除 Blob 数据是可行的？用户如何访问更早的 Blob？

Rollup 在链上发布其交易数据的加密承诺，同时通过数据 Blob 提供底层的原始交易数据。这种安排允许独立证明者验证承诺的准确性，或在必要时挑战不正确的数据。在网络层面，共识客户端会临时存储这些数据 Blob，并证明（Attest）该数据已在以太坊网络中传播并可用。为了防止节点随着时间的推移变得过于庞大且消耗资源，这些数据会在 18 天后自动清理（Pruning）。共识客户端提供的证明保证了证明者在此期间有充足的时间和访问权限来验证或挑战数据。在清理之后，实际数据可以继续由 Rollup 运营者、用户或其他第三方在链下存储。

长期存储并使历史数据易于访问有多种实际方法。例如，特定应用的协议（如各个 Rollup）可以要求其自身的节点保留与该应用相关的历史数据。由于历史数据的丢失不会给以太坊本身带来风险，而只会影响特定应用，因此由各应用独立管理其数据存储是合理的。其他潜在方案包括使用 BitTorrent 等去中心化系统（例如定期生成并分发 Blob 数据的每日快照），或利用以太坊的 Portal Network（该网络可以扩展以支持历史数据存储）。此外，区块浏览器、API 服务商或像 The Graph 这样的第三方索引平台也很可能会维护完整的档案。最后，进行数据分析的个人研究者、爱好者或学术机构也可以在本地保存完整的历史记录，从而从直接访问数据的便利性和性能提升中获益。

#### 与其每 Slot 分配 1 MB 带宽给 Blob，直接降低普通交易的 Calldata 成本难道不是更好吗？
这里的问题核心在于以太坊网络的平均负载与最坏情况（峰值）负载之间的差异。目前，以太坊区块的平均大小约为 90 KB；尽管在理论上，如果一个区块中的 3,600 万 Gas 全部用于 Calldata $^7$，其最大区块容量可达约 2 MB。以太坊偶尔也会处理接近这一最大容量的区块，且未出现重大问题。然而，如果我们简单地将 Calldata 的 Gas 成本降低 10 倍，虽然平均区块大小可能仍处于可控范围，但潜在的最坏情况区块容量将激增至约 20 MB，这将使以太坊网络不堪重负。

$^7$ Calldata 指交易中包含数据但不直接执行的部分，发布在链上主要用于记录和验证。

以太坊现有的 Gas 定价模型很难分别管理平均负载和最坏情况，因为这两者之间的比例取决于用户如何将 Gas 支出分配给 Calldata 和其他资源。结果是，以太坊必须基于最坏情况来定价 Gas，从而人为地将平均负载限制在网络实际承载能力之下。通过引入多维费用市场（Multidimensional Fee Market），让 Gas 定价能够明确区分不同的资源类型，我们可以更好地使网络平均使用率与其实际容量相匹配，从而安全地在每个区块中容纳更多数据。Proto-danksharding 和 EIP-4488 正是为解决这一问题而设计的两项提案，旨在优化以太坊的 Gas 定价模型。

> [!Warning]
> 请务必区分 EIP-4488 与 EIP-4844（感谢这些提案编号，起得简直一点都不让人困惑）。EIP-4488 是一项更早、更简单的尝试，旨在解决平均负载与最坏情况负载不匹配的问题。该提案目前已处于停滞状态，因此很可能永远不会被实施。相比之下，EIP-4844 已经正式上线运行。

此外，引入 Blob 还有一个深层动机：最终目标是允许节点无需下载所有数据 Blob。这一点可以通过 Blob 实现，但对于 Calldata 来说是无法做到的。

> [!Tip]
> 你可能还有很多疑问。欲获取答案，请参阅本章末尾列出的完整进一步阅读清单。

### 无状态以太坊 (Stateless Ethereum)

在性能适度的硬件上运行以太坊节点的能力，对于实现真正的去中心化至关重要。这是因为运行节点使用户能够通过加密检查独立验证区块链信息，而不是依赖第三方。运行节点还允许用户在没有中间人的情况下，直接向以太坊 P2P 网络提交交易。如果这些优势仅限于拥有昂贵设备的用户，那么真正的去中心化就无从谈起。因此，以太坊节点必须具备极低的计算和内存需求，理想情况下应能在手机、微型计算机（如树莓派）上运行，或者在家庭电脑后台无感运行。

如今，高昂的硬盘空间需求是阻碍用户运行以太坊节点的主要障碍。其核心原因在于节点需要存储以太坊庞大的状态数据（State Data），这对于正确处理新区块和交易至关重要。

虽然廉价硬盘可以存储旧数据，但它们的读写速度通常太慢，无法高效处理实时进入的区块。仅仅通过降低存储成本或提高效率只能提供暂时的缓解，因为以太坊状态数据的增长实际上是无上限的；存储需求会持续增加，迫使技术进步必须不断追赶。一个更具可持续性的方法是开发新的客户端方法，在不依赖本地存储数据的情况下验证区块和交易。

“无状态（Statelessness）”这个词可能有些误导，因为它实际上并未完全消除“状态”的概念。相反，它改变了以太坊节点管理状态数据的方式。无状态主要分为两种类型：弱无状态和强无状态。弱无状态（Weak Statelessness）允许大多数节点在不存储状态数据的情况下运行，而将该责任转移给少数专门的节点。相比之下，强无状态（Strong Statelessness）则完全取消了任何节点存储完整状态数据的要求。

> [!Tip]
> 在接下来的章节中，我们将详细解释弱无状态与强无状态。同样值得一提的是，正如我们刚才所言，这些并不是达成“无状态以太坊”的唯一途径；这里的无状态本质上意味着改变以太坊节点管理状态数据的方式。另一种实现方法是使用像 Helios 这样的轻客户端（Light Clients）。Helios 能将一个不可信的中心化 RPC 端点转换为对用户安全、不可篡改的本地 RPC。它的运行负荷极轻，足以在移动设备上运行，并且几乎不需要任何存储空间。

#### 弱无状态 (Weak Statelessness)
在第 14 章中简要提到的“弱无状态”，涉及对以太坊节点验证状态更新方式的改进，但它并未完全消除网络中存储状态的必要性。相反，它将存储完整状态数据的责任转移给了被称为“区块提议者”或“构建者”的专业节点。随后，网络中的所有其他节点都可以在无需本地维护完整状态数据的情况下验证区块。在弱无状态下，创建（提议）新区块需要完全访问以太坊的状态数据，而验证这些区块则可以在完全不存储任何状态的情况下完成。

弱无状态的实现依赖于以太坊客户端采用一种名为 Verkle 树（Verkle trees） 的新数据结构（将在下一节详细介绍）。Verkle 树取代了以太坊当前的状态存储结构，并允许创建极小的、固定大小的见证数据（Witnesses） $^8$。节点通过交换这些见证数据来验证区块，而无需参考本地数据库。此外，PBS（提议者与构建者分离） 也是必不可少的，因为它允许拥有更强硬件的专业节点——区块构建者——去处理维护完整状态数据这一密集任务，而普通节点则可以进行无状态运行。

$^8$ 验证区块意味着重新执行其交易、更新以太坊状态，并确认计算出的状态根（State Root）与区块提议者提供的状态根相匹配。目前的以太坊客户端需要将整个存储在本地的状态树（State Trie）来验证区块。见证数据仅包含执行区块内交易所需的必要状态数据部分。然而，在使用传统的梅克尔树（Merkle trees）时，这些见证数据会变得过于庞大，导致节点难以在以太坊 12 秒的 Slot（时隙）时间内快速下载并处理它们。这种限制会使拥有快速网络连接的节点更具优势，从而导致中心化。Verkle 树通过显著减小见证数据的大小解决了这一问题，从而在无需本地存储状态的情况下实现了无状态验证。

#### 建议译文Verkle 树 (Verkle Trees)
“Verkle 树”一词结合了“向量承诺（Vector Commitment）”和“梅克尔树（Merkle Tree，我们在第 14 章中解释过）”。Verkle 树对于实现以太坊无状态客户端至关重要，这些客户端可以在不本地存储整个以太坊状态的情况下验证区块。相反，这些客户端依赖于见证数据（Witnesses） $^9$ 以及确认其有效性的加密证明。极小的见证数据体积至关重要，因为见证数据必须在以太坊 12 秒的 Slot（时隙）内被节点高效地分发和处理。目前基于梅克尔树的状态数据结构产生的见证数据过于庞大，不适合进行无状态验证。Verkle 树通过显著减小见证数据体积解决了这一问题。

$^9$ 见证数据是执行区块交易所必需的状态数据的紧凑集合。

正如同名所示，Verkle 树使用向量承诺：即 KZG 多项式承诺。这是一种加密承诺，允许在不暴露整个数据集的情况下，高效证明大型数据集中特定位置的数据值。如图 16-6 所示，与梅克尔树目前使用的哈希相比，它们具有更好的扩展性和更快的计算速度。在梅克尔树中，我们只有梅克尔根（哈希），而在 Verkle 树中，我们还拥有向量承诺。

![Figure 16-6](<./images/figure 16-6.png>)

图 16-6. 梅克尔树与 Verkle 树对比

如果仅有哈希值，我们无法证明某个特定元素存在于数值向量的特定位置；你必须传输整个向量。但通过向量承诺和打开（Opening）——即整个数值向量的一小部分——便可以证明某个特定元素确实存在于那个特定的位置。

梅克尔树允许以太坊节点在不下载整个区块链的情况下验证部分数据。然而，当梅克尔树变得非常庞大时，证明（验证数据所需的信息）的体积也会显著增加。如图 16-7 所示，这些庞大的证明会拖慢网络速度，并随着以太坊规模的不断扩大，使维持效率变得愈发困难。

![Figure 16-7](<./images/figure 16-7.png>)

图 16-7. 梅克尔树证明大小

为了证明特定的叶子节点 X 存在于该梅克尔树中，必须传递该路径上所有给定节点的兄弟节点（Siblings）；这是因为如果没有这些数据片段，哈希运算将无法得出正确的结果。

Verkle 树通过显著减小这些证明的大小解决了这一问题。Verkle 树不再使用随着数据量增加而变大的证明，而是采用了一种称为向量承诺的加密方法。向量承诺允许你通过非常简短、紧凑的证明来证实海量数据的存在。这意味着即便以太坊区块链变得更加庞大，证明依然能保持小巧且高效，如图 16-8 所示。

![Figure 16-8](<./images/figure 16-8.png>)

图 16-8. Verkle 树证明大小对比

通过利用前文分析的向量承诺，我们可以避开不必要的数据，并显著减小 Verkle 树的证明大小。以下是梅克尔树的证明大小计算示例（请注意，证明大小是基于图 16-5 和 16-6 的参数计算的）：
* 梅克尔树：叶子数据加上 15 个兄弟节点（每一层深度都需要发送这些冗余数据，每个兄弟节点 32 字节），再乘以 7 层深度 = 1,000 个叶子节点需 3.58 MB。
* Verkle 树的证明大小则小得多：叶子数据加上一个承诺（32 字节）、一个数值（32 字节）以及一个索引（1 字节），乘以 4 层深度，再加上一些较小的常数级数据 = 1,000 个叶子节点仅需 150 KB。

在此解释之后，可能会产生一个小疑问：为什么计算梅克尔树时计入 7 层深度，而 Verkle 树只计入 4 层？答案非常简单：梅克尔树的每个节点只有 15 个兄弟节点（16 叉树），而 Verkle 树的节点拥有 255 个兄弟节点（256 叉树）。由于在相同深度下每一层的宽度都要大得多，Verkle 树可以存储多得多的数据。

Verkle 树将数据组织为（键，值）对，其中每个键（Key）为 32 字节，由一个 31 字节的“主干（Stem）”和一个 1 字节的“后缀（Suffix）”组成，如图 16-9 所示。这种键值方案的设计初衷是让位置接近的存储地址拥有相同的主干和不同的后缀，从而降低访问“邻近”存储位置的成本。

![Figure 16-9](<./images/figure 16-9.png>)

图 16-9. Verkle 树键结构

这些键（Keys）被组织为三种类型的节点：
* 扩展节点（Extension nodes，或称叶子节点）：代表一个“主干（Stem）”，最多可容纳 256 个不同的“后缀（Suffixes）”。
* 中间节点（Inner nodes）：包含最多 256 个子节点，子节点可以是其他中间节点或扩展节点。
* 空节点（Empty nodes）。

要构建一棵完整的 Verkle 树，需要从叶子节点开始，自底向上（Bottom-up）逐步计算多项式承诺，直到到达顶层的根承诺（Root Commitment）。这个根承诺简洁地代表了整棵树的所有数据，使节点能够仅通过引用这一个根承诺来快速验证区块链数据。当节点需要验证特定的区块链数据（如用户账户余额或交易有效性）时，它只需获取已知的根承诺以及一段极小的加密证明（通常仅几百字节）。

#### 强无状态 (Strong Statelessness)

强无状态彻底取消了节点存储任何状态数据的要求。在这种模式下，每一笔交易都会包含一小段见证数据（Witnesses），区块生产商可以将这些见证数据进行聚合。随后，这些生产商只需存储极少量的必要状态，以便为频繁访问的账户生成见证数据。这实际上将大部分状态管理的责任转移到了用户端，因为用户必须提供这些见证数据，并通过访问列表（Access Lists）精确指定其交易与之交互的账户及存储键。虽然这种方法能让节点变得极其轻量化，但它也引入了一定的权衡，尤其是增加了与智能合约交互时的复杂性和难度。

强无状态已在研究领域得到了探讨，但目前并未列入以太坊的近期路线图。以太坊更有可能追求弱无状态，因为在可预见的未来，弱无状态似乎已足以满足网络的扩容目标。

这段总结精准地概括了以太坊当前的以 Rollup 为中心的路线图 (Rollup-centric Roadmap)。为了符合以太坊中文社区的语境，我使用了诸如“数据可用性”、“模块化”和“去信任”等常用术语。

## 结语

以太坊的扩容方案不仅仅是为了提高速度，更是为了在不牺牲去中心化和安全性这两大核心价值的前提下，对整个系统进行全面升级。以太坊并没有采取权宜之计，而是通过 Rollups 和 Danksharding，并致力于实现无状态性 (Statelessness)，旨在构建一个分层体系，同时持续优化 L1（第一层） 主链。

在这种架构下，L2（第二层网络） 承担了大部分的执行工作，但仍然依赖以太坊底层（Base Layer）来保障安全性和最终确认性（Final Settlement）。这是一条深思熟虑的模块化 (Modular) 发展之路，在保持核心价值观不变的同时，为长期的增长与创新奠定了基础。

更多阅读资料：
* Danksharding 提案
* Proto-danksharding 提案
* EIP-4844（分片数据块交易）
* Danksharding（通俗易懂版）
* EIP-4488（降低交易调用数据费用）
* 助力无状态性的 Verkle 树 (Verkle Trees)
* Verkle 证明 (Verkle Proofs)
* Verkle 树相关 EIP
* Verkle 树结构详解
* 配对密码学报告：深入理解 BLS12-381 曲线
* BLS12-381 “简单易懂”版


