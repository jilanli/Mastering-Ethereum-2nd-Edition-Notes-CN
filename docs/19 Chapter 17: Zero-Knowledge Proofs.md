# 第 17 章：零知识证明 (Zero-Knowledge Proofs)

在本章中，我们将一同探索零知识证明 (ZK) 密码学那引人入胜的世界，并深入了解它是如何完美契合以太坊路线图的。正是这项技术，让以太坊实现真正的扩容 (Scaling) 并承载主流人群对区块空间的爆发式需求成为可能。
零知识技术是一个极其复杂的课题，其底层构建在大量的数学规律之上，我们无法在此穷尽所有细节。本章的目标是确保你能理解，为什么零知识密码学能为以太坊带来独特的机遇，以及它如何丝滑地融入其扩容路线图。
在本章结束时，你将从宏观层面掌握零知识密码学的运作机制，了解它的核心特性，以及以太坊将如何利用它来优化协议性能。

## 发展简史
零知识证明 (Zero-Knowledge Proofs) 最早由 Shafi Goldwasser、Silvio Micali 和 Charles Rackoff 在 1985 年发表的论文[《交互式证明系统的知识复杂度》](https://oreil.ly/a6KH6)中提出。在该论文中，他们将零知识证明描述为一种向对方证明“某件事是真实的”的方法，且除了“该声明确实属实”这一事实外，不会泄露任何其他信息。尽管零知识证明早在 20 世纪 80 年代就被发现，但其早期的实际应用场景非常有限。

一切在 2011 年迎来了转机。[BIT+11](https://oreil.ly/C6HvM) 论文引入了 SNARKs（简洁非交互式知识论证），为针对任意计算生成零知识证明提供了一个理论框架。两年后的 2013 年，[Pinocchio PGHR13](https://oreil.ly/4uU6x) 论文实现了首个通用型 SNARK 的工程化落地，使 SNARKs 在现实应用中变得可行。人类历史上第一次实现了：可以证明一个通用程序已被正确执行，而无需重新运行该程序，且无需泄露实际的计算细节。

一场革命就此拉开序幕。从那时起，零知识证明领域以惊人的速度演进：
* 2016 年：[Groth16 算法](https://oreil.ly/rxlOL)显著提升了 zk-SNARKs 的效率，缩减了证明大小 (Proof Size) 和验证时间 (Verification Time)。凭借其卓越的简洁性，Groth16 至今仍被广泛使用（例如去中心化混币应用 Tornado Cash 就在链上使用它）。
* 2017 年：[Bulletproofs](https://oreil.ly/ZUeIe) 带来了突破性进展，消除了对可信设置 (Trusted Setup) 的需求（我们将在后续章节深入探讨其定义），代价是证明体积较大。目前，隐私代币门罗币 (Monero) 使用它来混淆交易金额。
* 2018 年：[zk-STARKs](https://oreil.ly/TCnTT) 问世。它不仅不需要可信设置，还具备抗量子安全性 (Post-quantum Security)。它目前是以太坊 L2 项目 Starknet 的密码学基石。
* 2019 年：[PLONK](https://oreil.ly/3453_) 和 [Sonic](https://oreil.ly/f6_Sq) 作出了重大贡献，引入了通用且可更新的可信设置。这使得 SNARKs 在通用应用中更加灵活实用，并持续影响着现代 ZK 系统。

如今，零知识证明仍处于高速发展中。最近的进展聚焦于优化证明生成时间 (Proving Time)、递归效率 (Recursion Efficiency) 以及 zkEVM 和现代 zkVM 等实际应用。新的架构和优化方案层出不穷，不断推高零知识技术的边界。

这一领域的蓬勃发展主要得益于加密货币行业带来的资金注入。以太坊基金会 (EF) 自身也通过提供多项资助 (Grants) 以及设立专门的研究团队，持续为该课题贡献力量。

## 定义与特性

现在，让我们进入细节，明确什么是零知识证明以及它必须具备哪些特性。正如前文所述，零知识证明是一种协议，允许一方（通常称为证明者 Prover，简称 P）向另一方（通常称为验证者 Verifier，简称 V）证明某个陈述是真实的，且除了“该陈述确实为真”这一事实外，不泄露任何额外信息。

让我们将几个重要定义形式化：

**陈述 (Statement)**

正在被证明的断言。陈述是公开的，任何人都可以验证，且不包含任何私密信息。

**见证数据 (Witness)**

证明陈述属实的秘密信息。见证数据仅由证明者知晓。

**证明 (Proof)**

这是一个加密对象，它能在不泄露“见证数据”的前提下，让验证者确信陈述是真实的。

所有的零知识证明系统都必须遵循以下三个特性：

**完备性 (Completeness)**

如果证明者 P 手中的陈述是真实的，那么只要按照协议规则操作，P 就一定能计算出有效的零知识证明。不存在证明者遵守了所有规则却无法生成有效证明的情况。

**可靠性 (Soundness)**

任何恶意证明者都不可能为错误的陈述伪造出有效的证明。如果验证者接受了一个证明，那么唯一可能的解释就是证明者确实遵循了协议规则，并以真实的陈述为起点。

**零知识性 (Zero-knowledge)**

顾名思义，验证者在执行协议的过程中，除了获知初始陈述的有效性外，无法获取任何其他信息。

## 以太坊如何利用零知识证明

你可能会好奇，为什么这种极具前沿性的密码学技术对以太坊的未来发展和路线图如此重要。答案其实非常直接。

在以太坊的语境下，零知识证明系统的真正威力在于：它们使得验证一个陈述的有效性变得可能，而验证者无需亲自重复得出该陈述所需的全部计算过程。首先，由证明者（Prover）计算出某个特定的陈述并附带一份零知识证明；随后，所有的验证者（Verifiers）只需运行零知识协议，即可去信任化 (Trustlessly) 地确认该陈述属实，而无需像证明者那样进行同等规模的计算。

细心的读者可能已经发现，这与以太坊的某个环节完美契合：区块执行与状态更新——换句话说，就是 EVM 状态转换函数 (EVM State Transition Function)。每一个新区块都会通过处理其中包含的所有交易，来更新当前的以太坊状态。图 17-1 很好地展示了这一过程。

![Figure 17-1](<./images/figure 17-1.png>)

图 17-1：EVM 状态转换函数

你可以将 EVM（以太坊虚拟机） 想象成一个“黑盒”：它的输入是区块链的当前状态 (Current State) 和包含大量交易的新区块，输出则是更新后的新状态。目前，当一个以太坊全节点收到新区块时，它必须重新执行该区块中的所有交易，以便在无需依赖任何可信第三方的情况下，去信任化地更新状态。

这种方法的主要问题在于，区块执行成为了潜在的性能瓶颈，因为它属于计算密集型任务。你最终必须在“全节点为保持与主网同步所需的硬件配置”与“网络所需的去中心化程度”之间寻找平衡。如果你想通过提高全节点门槛来扩容，就会损害去中心化，因为财力有限的普通参与者将无法负担运行全节点的成本。反之，如果你为了让任何人都能运行节点而维持较低的硬件要求，那么区块链能够处理的最大吞吐量就会受到限制。以太坊始终倾向于去中心化这一侧，保持较低的硬件门槛，以支持单人质押 (Solo Stakers) 和全节点运行者的存在。

这正是零知识证明系统大显身手的地方。如果有一种方法，能让全节点在不执行任何交易的情况下（即无需进行沉重的 EVM 状态转换计算），就能去信任化地更新状态，结果会怎样？这个想法可以总结如下：
1. 执行与证明： 少数参与者通过执行新区块中的所有交易来完成实际的 EVM 计算，并生成链的更新状态。
2. 生成证明： 这些参与者生成一份零知识证明，用以证明该状态的有效性，并将其与更新后的状态一起分发给所有全节点。
3. 极速验证： 当其他全节点收到新的链状态和 ZK 证明时，它们只需验证证明的有效性。如果证明有效，它们就可以去信任化地将本地状态更新为收到的新状态。

通过这种方式，虽然仍需要一些节点（可能由财力雄厚的机构维护）来执行所有交易，但其他所有节点都可以维持极低的运行成本，因为它们只需验证证明。你可以大幅提升第一类节点的硬件要求，从而处理极高的吞吐量，同时凭借零知识证明的“魔法”依然保持高度的去中心化。

到目前为止，我们一直假设生成和验证 ZK 证明是快速且简便的。事实上，只有当“验证 ZK 证明”比“重新执行区块内所有交易”快得多时，上述方案才有意义。就现状而言，实现这一特性仍具挑战。但这本质上是一个工程优化问题：这只是“何时”实现的问题，而不是“能否”实现的问题。我们很快就会达到那个临界点——能够实时为以太坊区块生成并验证零知识证明。如果你对该领域的进展感兴趣，Ethproofs 是一个非常值得关注的网站。

## L2 同样受益于 ZK 技术
以太坊主网并不是零知识证明技术的唯一受益者。事实上，正如你在第 16 章中可能已经读到的，有一类被称为 ZK-rollups 的汇总网络。顾名思义，它们利用零知识证明系统来证明 EVM 的执行过程，从而向主链提交其状态更新，并附带一份确保新状态计算正确的零知识证明。

你可能会纳闷：既然前面提到目前还无法实现以太坊区块的实时证明，那 ZK-rollups 又是如何使用这项技术的呢？答案是：它们并没有追求实时证明，甚至不需要为 L2 的每一个区块都进行实时证明。通常，它们每隔一小时左右提交一次聚合零知识证明 (Aggregate ZK-proof)，用以证明自上次更新以来到最新状态之间的所有状态变更都是正确执行的。

每份零知识证明之间的时间间隔，仅会影响 Rollup 本身的最终确认性 (Finality) 时间。如果每小时提交一次证明，这意味着平均而言，你需要等待 30 分钟，你的交易才能在 L1（第一层主网）上被视为真正的“最终确认”。

## 一个小案例
为了更直观地理解零知识证明系统是如何运作的，让我们从一个简单的小例子开始：划分问题 (Partition Problem)。这是一个著名的数学问题，其任务是：“判断一个给定的正整数多重集 $S$ 是否可以被划分为两个子集 $S_1$ 和 $S_2$，使得 $S_1$ 中所有数字之和等于 $S_2$ 中所有数字之和。”

> [!Note]
> 划分问题属于判定问题 (Decision Problem)，而以太坊依赖零知识证明来验证的是执行轨迹 (Execution Traces)。尽管以太坊使用 ZKP 的主要场景是验证计算执行过程，但通过划分问题来推演，仍然是建立“零知识证明系统如何工作”直观认知的绝佳方式。

假设我们有一个集合 $S = [1, 1, 5, 7]$，我们可以通过将其划分为 $S_1 = [1, 1, 5]$ 和 $S_2 = [7]$ 来满足要求（两边之和均为 7）。但并不是所有的集合都能找到正确解，例如，如果 $S = [1, 1, 5, 8]$，那么由于总和为奇数，根本无法将其划分为两个和相等的子集。

划分问题是 NP 完全 (NP-complete) 的。这意味着目前不存在能在多项式时间内解决该问题的算法——也就是说，如果存在解，目前没有办法在极短的时间内找到它，或者证明解不存在。

### 让我们来证明它

划分问题的结构完美契合了我们之前看到的零知识证明系统的特性。事实上，既然找到解的过程非常困难，那么将“寻找解”的计算压力外包给一个配备了超级计算机的、资源丰富的证明者 (Prover) 就会变得非常有意义。接着，利用零知识技术，证明者可以向所有人证明它确实找到了一个有效解，而无需其他人进行同样繁重的计算，同时也不会泄露该解的具体内容。

为了让划分问题适配零知识证明系统，我们需要对其进行一点小小的改动。假设我们有一个正整数列表 $s$。如果另一个列表 $a$ 满足以下条件，我们就称其为满足赋值 (Satisfying Assignment)：
1. 长度相等： len(s) == len(a)
2. 元素限定： $a$ 中的所有元素必须是 $1$ 或 $-1$
3. 点积为零： $s$ 和 $a$ 的点积为 $0$

请注意，这种构造方式与之前的划分问题是完全等价的。如果我们沿用之前的初始列表 $S = [1, 1, 5, 7]$，那么对应的满足赋值 $a$ 就是：

$$a = [1, 1, 1, -1]$$

你可以手动校验这三个条件是否全部成立：
1. len(s) = 4 且 len(a) = 4（成立）
2. $a$ 的元素全是 $1$ 或 $-1$（成立）
3. 点积： $1 \times 1 + 1 \times 1 + 1 \times 5 + (-1) \times 7 = 1 + 1 + 5 - 7 = 0$（成立）

两个等长列表之间的点积 (Dot Product) 的计算方法是：将第一个列表中的每个成员与第二个列表中的对应元素相乘，然后将所有结果相加。从技术角度来说，如果我们有两个长度均为 $n$ 的列表 $s = [s_0, s_1, s_2, \dots, s_n]$ 和 $a = [a_0, a_1, a_2, \dots, a_n]$，则点积的计算公式如下：

$$s \cdot a = \sum_{i=0}^{n} s_i a_i = s_0 a_0 + s_1 a_1 + s_2 a_2 + \dots + s_n a_n$$

当然，我们可以直接把列表 $a$ 发送给验证者，让他们直接校验这是否为一个有效解。但这样做会泄露解的具体内容，从而违反了零知识证明中“不泄露任何信息”的初衷。为此，我们开始生成另一个列表 $w$，即部分和列表 (Partial-sum list)。也就是说，$w[i]$ 等于列表 $s$ 和 $a$ 截至索引 $i$ 的部分点积。在零知识证明系统的语境下，$w$ 也被称为见证数据 (Witness)。沿用之前的例子，我们可以计算出 $w$：

$$w = [1, 2, 7, 0]$$

请注意，如果 $a$ 是一个有效的“满足赋值”，那么 $w$ 的最后一个元素必定为 $0$（因为点积为 $0$）。为了让证明系统更高效地运行，我们对目前构建的证明过程进行一点小小的修改。具体来说，我们将列表 $w$ 的最后一个元素移动到首位，因此之前的 $w$ 现在变成了：

$$w = [0, 1, 2, 7]$$

太棒了！这个列表 $w$ 具有一个非常酷的特性：

$$|s[i]| = |w[i + 1] - w[i]|$$

你可以亲自校验一下这个等式的有效性：

$$|s[0]| = |w[1] - w[0]| = |1 - 0| = |1| = 1$$

$$|s[1]| = |w[2] - w[1]| = |2 - 1| = |1| = 1$$

$$|s[2]| = |w[3] - w[2]| = |7 - 2| = |5| = 5$$

$$|s[3]| = |w[0] - w[3]| = |0 - 7| = |-7| = 7$$

请注意，在计算 $s[3]$ 时，我们需要访问 $w[4]$，但由于 $w$ 只有四个元素（且索引从 $0$ 开始）， $w[4]$ 并不存在。不过，这里有一个非常简单的解决方案：你只需要像对待循环列表 (Cyclical List) 一样，回到 $w$ 的第一个元素即可。

验证者可以要求查看 $w$ 中任意两个相邻的元素，并检查上述关系是否成立。请记住，验证者是有权访问列表 $s$ 的，因为 $s$ 是公开可见的，它代表了这个问题的输入；但验证者无法访问 $a$（即满足赋值），因为 $a$ 代表了解析方案。如果等式成立，则意味着证明者确实知道该问题的一个有效解 $a$。

#### 存在的问题
到目前为止，我们构建的是一个非常原始（Naive）的证明系统。事实上，它存在三个严重的问题：
1. 概率可靠性不足： 此前我们假设，一旦验证者请求了 $w$ 的两个相邻元素且等式成立，就完成了验证。但这并不严谨。仅凭一次查询，验证者无法完全确定；他们必须对 $w$ 的相邻元素进行多次随机查询，才能以极高的概率确认证明者没有作弊。
2. 缺乏数据承诺（一致性问题）： 虽然验证者可以校验解的正确性，但该系统高度依赖证明者的诚信。如果证明者心怀不轨呢？当验证者请求 $w$ 的两个相邻元素时，证明者可能会临时编造两个恰好满足等式的随机数，而不是基于同一组固定的 $w$ 列表进行回答。
3. 违反零知识原则： 最重要的是，这个系统并不是零知识的。通过询问 $w$ 的连续元素，验证者实际上获取了关于“满足赋值 $a$”的大量信息。验证者知道 $w$ 的构造方式，因此他们掌握的 $w$ 越多，推断出最终解 $a$ 的可能性就越大。现在，让我们着手解决这些问题，尝试构建一个更完善的证明系统。

### 零知识化 (Zero Knowledge)
现在，让我们为系统引入“零知识性”。我们目前构建的协议存在一个核心缺陷：我们将 $w$ 的真实数值直接发送给了验证者，这会导致验证者推断出关于 $a$ 的大量信息。为了在实践中观察这一点，让我们模拟证明者与验证者之间的两步交互。
1. 第一步交互： 验证者请求 $w[1]$ 和 $w[2]$，并检查 $|w[2] - w[1]| = |s[1]|$ 是否成立。证明者提供了 $w[1] = 1$ 和 $w[2] = 2$。验证者确认等式成立：

$$|s[1]| = |w[2] - w[1]| = |2 - 1| = 1 = 1$$
   
2. 第二步交互： 接着，验证者发起了另一次查询：请求 $w[2]$ 和 $w[3]$。证明者提供了 $w[2] = 2$ 和 $w[3] = 7$。验证者校验等式：

$$|s[2]| = |w[3] - w[2]| = |7 - 2| = 5 = 5$$

通过这两次交互，验证者已经掌握了 $w$ 中的三个元素：

$w[1]=1$

$w[2]=2$

$w[3]=7$

由于验证者已经知道了 $s = [1, 1, 5, 7]$ 并且了解 $w$ 的计算方式，他们可以推导出解 $a$ 的初始部分等于 $[1, 1, 1]$，因为这是得到 $w[3] = 7$、 $w[2] = 2$ 和 $w[1] = 1$ 的唯一途径。

我们需要找到一种方法来掩盖 $w$ 的真实值，但同时又能让新的 $w$ 与输入列表 $s$ 之间满足原有的关系。为了实现这一点，我们需要以一种非常特殊的方式加入随机性 (Randomness)。符号翻转： 

首先，针对列表 $a$，我们抛一枚硬币。如果是正面，保持原样；如果是反面，我们将所有元素的符号取反（即 $1$ 变成 $-1$， $-1$ 变成 $1$）。请注意，这种改变并不会破坏该问题中“满足赋值 $a$”的三大核心性质（点积依然为 $0$）。

接着，我们选取一个随机整数 $r$。我们按照之前的方法计算 $w$，但要在 $w$ 的每一个元素上都加上这个 $r$。即便做了这些改动， $s$ 和 $w$ 之间的核心关系（差值的绝对值等于 $s[i]$）依然成立。

每当验证者发起一次新的查询，我们（证明者）都必须重新抛一次硬币，并重新计算一个不同的随机值 $r$。通过这种方式，验证者虽然仍能校验等式的有效性，但他们无法获取关于 $a$ 的任何有效信息，因为所有的 $w$ 值在他们看来都是随机的。

让我们做一个小演示。请记住，作为证明者的我们，手中同时持有 $s$ 和 $a$：

$$s = [1, 1, 5, 7]$$

$$a = [1, 1, 1, -1]$$

现在，验证者请求获取 $w[1]$ 和 $w[2]$，以校验 $|w[2] - w[1]| = |s[1]|$ 是否成立。

首先，我们需要抛硬币来决定是否更改 $a$ 的所有数值。结果是反面，所以我们需要翻转所有符号，$a$ 变成了：

$$a' = [-1, -1, -1, 1]$$

接着，我们计算出一个随机值 $r = 4$。按照之前的方法计算 $w$，并给其中的每一个元素都加上 $r$：

$$w = [0, -1, -2, 7]$$

$$w' = [4, 3, 2, -3]$$

我们提供 $w'[1] = 3$ 和 $w'[2] = 2$ 给验证者。

验证者依然可以确认等式的有效性：

$$|w'[2] - w'[1]| = |2 - 3| = |-1| = 1$$

现在，验证者进行了另一次查询，请求获取 $w[2]$ 和 $w[3]$。同样地，我们需要抛硬币来决定是否更改 $a$ 的所有数值。这次是正面，所以我们不改变符号。

接着，我们计算出一个随机值 $r = 1$。我们计算 $w$ 并给每个元素加上 $r$：

$$a = [1, 1, 1, -1]$$

我们提供 $w''[2] = 3$ 和 $w''[3] = 8$。验证者依然可以确认等式的有效性：

$$|s[2]| = |w''[3] - w''[2]| = |8 - 3| = 5$$

但现在，验证者无法获取关于满足赋值 $a$ 的有效信息。事实上，他们现在掌握的信息如下：

$$w'[1] = 3$$

$$w'[2] = 2$$

$$w''[2] = 3$$

$$w''[3] = 8$$

对于验证者来说，不同查询中得到的 $w$ 值看起来都是随机的，因此他们无法还原出赋值方案 $a$。

太棒了！我们成功地为证明系统引入了零知识性。现在，让我们来解决“恶意证明者”的问题。

#### 证明者承诺 (Prover Commitment)
我们需要解决的问题是，证明者可能会欺骗验证者，提供完全编造的数字，而不是计算出的见证值 $w$ 的真实数值。这非常糟糕，因为证明者将能够为虚假陈述提供有效的证明——也就是说，即使证明者实际上并没有满足条件的赋值 $a$，他们也有可能诱导验证者相信他们确实拥有。

我们需要找到一种方法，确保证明者无法在不被发现的情况下撒谎。从本质上讲，我们需要证明者在向验证者提供所有 $w$ 值之前，先对这些值进行承诺（commitment）。

这正是默克尔树（Merkle trees）再次发挥作用的地方。我们在第 14 章介绍过它们，所以在这里不再详细讨论它们的工作原理。

让我们通过一个新示例来看看实践中的新构造。我们（证明者）拥有：

$$s=[1,1,5,7]$$

$$a=[1,1,1,−1]$$

我们抛硬币，结果是正面，所以我们不需要更改赋值方案 $a$ 的正负号。接着，我们通过计算 $a$ 和 $s$ 的点积（在首尾元素之间进行切换/累加）来计算 $w$：

$$w = [0, 1, 2, 7]$$

我们计算出一个随机值 $r = 8$，并将其加到 $w$ 的每个元素中：

$$w' = [8, 9, 10, 15]$$

现在我们需要对 $w'$ 的所有数值进行承诺，并将该承诺发送给验证者，以此确保如果我们通过提供虚假的 $w'$ 值进行欺骗，这种行为将能被轻易发现。图 17-2 展示了以 $w'$ 的所有数值作为叶子节点所构建的默克尔树。

![Figure 17-2](<./images/figure 17-2.png>)
图 17-2. 使用 $w'$ 值构建的默克尔树

默克尔根（Merkle root）是最终发送给验证者的承诺（commitment）。
